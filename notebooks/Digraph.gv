digraph {
	graph [size="449.84999999999997,449.84999999999997"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1844707884496 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	1846552194992 [label=AddmmBackward0]
	1846552195904 -> 1846552194992
	1846371436080 [label="head.fc2.bias
 (1)" fillcolor=lightblue]
	1846371436080 -> 1846552195904
	1846552195904 [label=AccumulateGrad]
	1846552447104 -> 1846552194992
	1846552447104 [label=NativeLayerNormBackward0]
	1846552455888 -> 1846552447104
	1846552455888 [label=GeluBackward0]
	1846552448880 -> 1846552455888
	1846552448880 [label=AddmmBackward0]
	1846552453056 -> 1846552448880
	1846371436000 [label="head.fc1.bias
 (2304)" fillcolor=lightblue]
	1846371436000 -> 1846552453056
	1846552453056 [label=AccumulateGrad]
	1846552447152 -> 1846552448880
	1846552447152 [label=MeanBackward1]
	1846506518848 -> 1846552447152
	1846506518848 [label=AddBackward0]
	1846506518608 -> 1846506518848
	1846506518608 [label=MulBackward0]
	1844708100992 -> 1846506518608
	1844708100992 [label=ConvolutionBackward0]
	1844708098976 -> 1844708100992
	1844708098976 [label=GeluBackward0]
	1844708102576 -> 1844708098976
	1844708102576 [label=ConvolutionBackward0]
	1844708100128 -> 1844708102576
	1844708100128 [label=NativeBatchNormBackward0]
	1844708099360 -> 1844708100128
	1844708099360 [label=CatBackward0]
	1844708100416 -> 1844708099360
	1844708100416 [label=SplitWithSizesBackward0]
	1846506518896 -> 1844708100416
	1846506518896 [label=AddBackward0]
	1844708101280 -> 1846506518896
	1844708101280 [label=MulBackward0]
	1844708100224 -> 1844708101280
	1844708100224 [label=ConvolutionBackward0]
	1844708102960 -> 1844708100224
	1844708102960 [label=GeluBackward0]
	1844708104112 -> 1844708102960
	1844708104112 [label=ConvolutionBackward0]
	1844708103152 -> 1844708104112
	1844708103152 [label=NativeBatchNormBackward0]
	1844708101424 -> 1844708103152
	1844708101424 [label=CatBackward0]
	1844708102864 -> 1844708101424
	1844708102864 [label=SplitWithSizesBackward0]
	1844708100944 -> 1844708102864
	1844708100944 [label=AddBackward0]
	1844708102816 -> 1844708100944
	1844708102816 [label=MulBackward0]
	1844708104496 -> 1844708102816
	1844708104496 [label=ConvolutionBackward0]
	1844708102432 -> 1844708104496
	1844708102432 [label=GeluBackward0]
	1844708105984 -> 1844708102432
	1844708105984 [label=ConvolutionBackward0]
	1844708104784 -> 1844708105984
	1844708104784 [label=NativeBatchNormBackward0]
	1844708105600 -> 1844708104784
	1844708105600 [label=CatBackward0]
	1844708103296 -> 1844708105600
	1844708103296 [label=SplitWithSizesBackward0]
	1844708102096 -> 1844708103296
	1844708102096 [label=ConvolutionBackward0]
	1844708104208 -> 1844708102096
	1844708104208 [label=NativeBatchNormBackward0]
	1844708105408 -> 1844708104208
	1844708105408 [label=AddBackward0]
	1844708106608 -> 1844708105408
	1844708106608 [label=MulBackward0]
	1844708106944 -> 1844708106608
	1844708106944 [label=ConvolutionBackward0]
	1844708106272 -> 1844708106944
	1844708106272 [label=GeluBackward0]
	1844708106848 -> 1844708106272
	1844708106848 [label=ConvolutionBackward0]
	1844708107232 -> 1844708106848
	1844708107232 [label=NativeBatchNormBackward0]
	1844708107040 -> 1844708107232
	1844708107040 [label=CatBackward0]
	1844708107424 -> 1844708107040
	1844708107424 [label=SplitWithSizesBackward0]
	1844708106032 -> 1844708107424
	1844708106032 [label=AddBackward0]
	1844708107808 -> 1844708106032
	1844708107808 [label=MulBackward0]
	1844708107952 -> 1844708107808
	1844708107952 [label=ConvolutionBackward0]
	1844708108288 -> 1844708107952
	1844708108288 [label=GeluBackward0]
	1844708108144 -> 1844708108288
	1844708108144 [label=ConvolutionBackward0]
	1844708108432 -> 1844708108144
	1844708108432 [label=NativeBatchNormBackward0]
	1844708108624 -> 1844708108432
	1844708108624 [label=CatBackward0]
	1844708108816 -> 1844708108624
	1844708108816 [label=SplitWithSizesBackward0]
	1844708107856 -> 1844708108816
	1844708107856 [label=AddBackward0]
	1844708109104 -> 1844708107856
	1844708109104 [label=MulBackward0]
	1844708109248 -> 1844708109104
	1844708109248 [label=ConvolutionBackward0]
	1844708109392 -> 1844708109248
	1844708109392 [label=GeluBackward0]
	1844708109584 -> 1844708109392
	1844708109584 [label=ConvolutionBackward0]
	1844708109680 -> 1844708109584
	1844708109680 [label=NativeBatchNormBackward0]
	1844708109872 -> 1844708109680
	1844708109872 [label=CatBackward0]
	1844708110064 -> 1844708109872
	1844708110064 [label=SplitWithSizesBackward0]
	1844708108960 -> 1844708110064
	1844708108960 [label=AddBackward0]
	1844708110352 -> 1844708108960
	1844708110352 [label=MulBackward0]
	1844708110496 -> 1844708110352
	1844708110496 [label=ConvolutionBackward0]
	1844708110640 -> 1844708110496
	1844708110640 [label=GeluBackward0]
	1844708110832 -> 1844708110640
	1844708110832 [label=ConvolutionBackward0]
	1844708110928 -> 1844708110832
	1844708110928 [label=NativeBatchNormBackward0]
	1844708111120 -> 1844708110928
	1844708111120 [label=CatBackward0]
	1844708111312 -> 1844708111120
	1844708111312 [label=SplitWithSizesBackward0]
	1844708110208 -> 1844708111312
	1844708110208 [label=AddBackward0]
	1844708111600 -> 1844708110208
	1844708111600 [label=MulBackward0]
	1844708111744 -> 1844708111600
	1844708111744 [label=ConvolutionBackward0]
	1844708111888 -> 1844708111744
	1844708111888 [label=GeluBackward0]
	1844708112080 -> 1844708111888
	1844708112080 [label=ConvolutionBackward0]
	1844708112176 -> 1844708112080
	1844708112176 [label=NativeBatchNormBackward0]
	1844708112368 -> 1844708112176
	1844708112368 [label=CatBackward0]
	1844708112560 -> 1844708112368
	1844708112560 [label=SplitWithSizesBackward0]
	1844708111456 -> 1844708112560
	1844708111456 [label=AddBackward0]
	1844708112848 -> 1844708111456
	1844708112848 [label=MulBackward0]
	1844708112992 -> 1844708112848
	1844708112992 [label=ConvolutionBackward0]
	1844708113136 -> 1844708112992
	1844708113136 [label=GeluBackward0]
	1844708113328 -> 1844708113136
	1844708113328 [label=ConvolutionBackward0]
	1844708113424 -> 1844708113328
	1844708113424 [label=NativeBatchNormBackward0]
	1844708113616 -> 1844708113424
	1844708113616 [label=CatBackward0]
	1844708113808 -> 1844708113616
	1844708113808 [label=SplitWithSizesBackward0]
	1844708112704 -> 1844708113808
	1844708112704 [label=AddBackward0]
	1844708114096 -> 1844708112704
	1844708114096 [label=MulBackward0]
	1844708114240 -> 1844708114096
	1844708114240 [label=ConvolutionBackward0]
	1844708114384 -> 1844708114240
	1844708114384 [label=GeluBackward0]
	1844708557008 -> 1844708114384
	1844708557008 [label=ConvolutionBackward0]
	1844708557104 -> 1844708557008
	1844708557104 [label=NativeBatchNormBackward0]
	1844708557296 -> 1844708557104
	1844708557296 [label=CatBackward0]
	1844708557488 -> 1844708557296
	1844708557488 [label=SplitWithSizesBackward0]
	1844708113952 -> 1844708557488
	1844708113952 [label=AddBackward0]
	1844708557776 -> 1844708113952
	1844708557776 [label=MulBackward0]
	1844708557920 -> 1844708557776
	1844708557920 [label=ConvolutionBackward0]
	1844708558064 -> 1844708557920
	1844708558064 [label=GeluBackward0]
	1844708558256 -> 1844708558064
	1844708558256 [label=ConvolutionBackward0]
	1844708558352 -> 1844708558256
	1844708558352 [label=NativeBatchNormBackward0]
	1844708558544 -> 1844708558352
	1844708558544 [label=CatBackward0]
	1844708558736 -> 1844708558544
	1844708558736 [label=SplitWithSizesBackward0]
	1844708557632 -> 1844708558736
	1844708557632 [label=AddBackward0]
	1844708559024 -> 1844708557632
	1844708559024 [label=MulBackward0]
	1844708559168 -> 1844708559024
	1844708559168 [label=ConvolutionBackward0]
	1844708559312 -> 1844708559168
	1844708559312 [label=GeluBackward0]
	1844708559504 -> 1844708559312
	1844708559504 [label=ConvolutionBackward0]
	1844708559600 -> 1844708559504
	1844708559600 [label=NativeBatchNormBackward0]
	1844708559792 -> 1844708559600
	1844708559792 [label=CatBackward0]
	1844708559984 -> 1844708559792
	1844708559984 [label=SplitWithSizesBackward0]
	1844708558880 -> 1844708559984
	1844708558880 [label=AddBackward0]
	1844708560272 -> 1844708558880
	1844708560272 [label=MulBackward0]
	1844708560416 -> 1844708560272
	1844708560416 [label=ConvolutionBackward0]
	1844708560560 -> 1844708560416
	1844708560560 [label=GeluBackward0]
	1844708560752 -> 1844708560560
	1844708560752 [label=ConvolutionBackward0]
	1844708560848 -> 1844708560752
	1844708560848 [label=NativeBatchNormBackward0]
	1844708561040 -> 1844708560848
	1844708561040 [label=CatBackward0]
	1844708561232 -> 1844708561040
	1844708561232 [label=SplitWithSizesBackward0]
	1844708560128 -> 1844708561232
	1844708560128 [label=AddBackward0]
	1844708561520 -> 1844708560128
	1844708561520 [label=MulBackward0]
	1844708561664 -> 1844708561520
	1844708561664 [label=ConvolutionBackward0]
	1844708561808 -> 1844708561664
	1844708561808 [label=GeluBackward0]
	1844708562000 -> 1844708561808
	1844708562000 [label=ConvolutionBackward0]
	1844708562096 -> 1844708562000
	1844708562096 [label=NativeBatchNormBackward0]
	1844708562288 -> 1844708562096
	1844708562288 [label=CatBackward0]
	1844708562480 -> 1844708562288
	1844708562480 [label=SplitWithSizesBackward0]
	1844708561376 -> 1844708562480
	1844708561376 [label=AddBackward0]
	1844708562768 -> 1844708561376
	1844708562768 [label=MulBackward0]
	1844708562912 -> 1844708562768
	1844708562912 [label=ConvolutionBackward0]
	1844708563056 -> 1844708562912
	1844708563056 [label=GeluBackward0]
	1844708563248 -> 1844708563056
	1844708563248 [label=ConvolutionBackward0]
	1844708563344 -> 1844708563248
	1844708563344 [label=NativeBatchNormBackward0]
	1844708563536 -> 1844708563344
	1844708563536 [label=CatBackward0]
	1844708563728 -> 1844708563536
	1844708563728 [label=SplitWithSizesBackward0]
	1844708562624 -> 1844708563728
	1844708562624 [label=AddBackward0]
	1844708564016 -> 1844708562624
	1844708564016 [label=MulBackward0]
	1844708564160 -> 1844708564016
	1844708564160 [label=ConvolutionBackward0]
	1844708564304 -> 1844708564160
	1844708564304 [label=GeluBackward0]
	1844708564496 -> 1844708564304
	1844708564496 [label=ConvolutionBackward0]
	1844708564592 -> 1844708564496
	1844708564592 [label=NativeBatchNormBackward0]
	1844708564784 -> 1844708564592
	1844708564784 [label=CatBackward0]
	1844708564976 -> 1844708564784
	1844708564976 [label=SplitWithSizesBackward0]
	1844708563872 -> 1844708564976
	1844708563872 [label=AddBackward0]
	1844708565264 -> 1844708563872
	1844708565264 [label=MulBackward0]
	1844708565408 -> 1844708565264
	1844708565408 [label=ConvolutionBackward0]
	1844708565552 -> 1844708565408
	1844708565552 [label=GeluBackward0]
	1844708565744 -> 1844708565552
	1844708565744 [label=ConvolutionBackward0]
	1844708565840 -> 1844708565744
	1844708565840 [label=NativeBatchNormBackward0]
	1844708566032 -> 1844708565840
	1844708566032 [label=CatBackward0]
	1844708566224 -> 1844708566032
	1844708566224 [label=SplitWithSizesBackward0]
	1844708565120 -> 1844708566224
	1844708565120 [label=AddBackward0]
	1844708566512 -> 1844708565120
	1844708566512 [label=MulBackward0]
	1844708566656 -> 1844708566512
	1844708566656 [label=ConvolutionBackward0]
	1844708566800 -> 1844708566656
	1844708566800 [label=GeluBackward0]
	1844708566992 -> 1844708566800
	1844708566992 [label=ConvolutionBackward0]
	1844708567088 -> 1844708566992
	1844708567088 [label=NativeBatchNormBackward0]
	1844708567280 -> 1844708567088
	1844708567280 [label=CatBackward0]
	1844708567472 -> 1844708567280
	1844708567472 [label=SplitWithSizesBackward0]
	1844708566368 -> 1844708567472
	1844708566368 [label=AddBackward0]
	1844708567760 -> 1844708566368
	1844708567760 [label=MulBackward0]
	1844708567904 -> 1844708567760
	1844708567904 [label=ConvolutionBackward0]
	1844708568048 -> 1844708567904
	1844708568048 [label=GeluBackward0]
	1844708568240 -> 1844708568048
	1844708568240 [label=ConvolutionBackward0]
	1844708568336 -> 1844708568240
	1844708568336 [label=NativeBatchNormBackward0]
	1844708568528 -> 1844708568336
	1844708568528 [label=CatBackward0]
	1844708568720 -> 1844708568528
	1844708568720 [label=SplitWithSizesBackward0]
	1844708567616 -> 1844708568720
	1844708567616 [label=AddBackward0]
	1844708569008 -> 1844708567616
	1844708569008 [label=MulBackward0]
	1844708569152 -> 1844708569008
	1844708569152 [label=ConvolutionBackward0]
	1844708569296 -> 1844708569152
	1844708569296 [label=GeluBackward0]
	1844708569488 -> 1844708569296
	1844708569488 [label=ConvolutionBackward0]
	1844708569584 -> 1844708569488
	1844708569584 [label=NativeBatchNormBackward0]
	1844708569776 -> 1844708569584
	1844708569776 [label=CatBackward0]
	1844708569968 -> 1844708569776
	1844708569968 [label=SplitWithSizesBackward0]
	1844708568864 -> 1844708569968
	1844708568864 [label=AddBackward0]
	1844708570256 -> 1844708568864
	1844708570256 [label=MulBackward0]
	1844708570400 -> 1844708570256
	1844708570400 [label=ConvolutionBackward0]
	1844708570544 -> 1844708570400
	1844708570544 [label=GeluBackward0]
	1844708570736 -> 1844708570544
	1844708570736 [label=ConvolutionBackward0]
	1844708570832 -> 1844708570736
	1844708570832 [label=NativeBatchNormBackward0]
	1844708571024 -> 1844708570832
	1844708571024 [label=CatBackward0]
	1844708571216 -> 1844708571024
	1844708571216 [label=SplitWithSizesBackward0]
	1844708570112 -> 1844708571216
	1844708570112 [label=AddBackward0]
	1844708571504 -> 1844708570112
	1844708571504 [label=MulBackward0]
	1844708571648 -> 1844708571504
	1844708571648 [label=ConvolutionBackward0]
	1844708571792 -> 1844708571648
	1844708571792 [label=GeluBackward0]
	1844708571984 -> 1844708571792
	1844708571984 [label=ConvolutionBackward0]
	1844708572080 -> 1844708571984
	1844708572080 [label=NativeBatchNormBackward0]
	1844708572272 -> 1844708572080
	1844708572272 [label=CatBackward0]
	1844708572464 -> 1844708572272
	1844708572464 [label=SplitWithSizesBackward0]
	1844708571360 -> 1844708572464
	1844708571360 [label=AddBackward0]
	1844708572752 -> 1844708571360
	1844708572752 [label=MulBackward0]
	1844708572896 -> 1844708572752
	1844708572896 [label=ConvolutionBackward0]
	1844708573040 -> 1844708572896
	1844708573040 [label=GeluBackward0]
	1844708573136 -> 1844708573040
	1844708573136 [label=ConvolutionBackward0]
	1844738474192 -> 1844708573136
	1844738474192 [label=NativeBatchNormBackward0]
	1844738474384 -> 1844738474192
	1844738474384 [label=CatBackward0]
	1844738474576 -> 1844738474384
	1844738474576 [label=SplitWithSizesBackward0]
	1844708572608 -> 1844738474576
	1844708572608 [label=AddBackward0]
	1844738474864 -> 1844708572608
	1844738474864 [label=MulBackward0]
	1844738475008 -> 1844738474864
	1844738475008 [label=ConvolutionBackward0]
	1844738475152 -> 1844738475008
	1844738475152 [label=GeluBackward0]
	1844738475344 -> 1844738475152
	1844738475344 [label=ConvolutionBackward0]
	1844738475440 -> 1844738475344
	1844738475440 [label=NativeBatchNormBackward0]
	1844738475632 -> 1844738475440
	1844738475632 [label=CatBackward0]
	1844738475824 -> 1844738475632
	1844738475824 [label=SplitWithSizesBackward0]
	1844738474720 -> 1844738475824
	1844738474720 [label=AddBackward0]
	1844738476112 -> 1844738474720
	1844738476112 [label=MulBackward0]
	1844738476256 -> 1844738476112
	1844738476256 [label=ConvolutionBackward0]
	1844738476400 -> 1844738476256
	1844738476400 [label=GeluBackward0]
	1844738476592 -> 1844738476400
	1844738476592 [label=ConvolutionBackward0]
	1844738476688 -> 1844738476592
	1844738476688 [label=NativeBatchNormBackward0]
	1844738476880 -> 1844738476688
	1844738476880 [label=CatBackward0]
	1844738477072 -> 1844738476880
	1844738477072 [label=SplitWithSizesBackward0]
	1844738475968 -> 1844738477072
	1844738475968 [label=AddBackward0]
	1844738477360 -> 1844738475968
	1844738477360 [label=MulBackward0]
	1844738477504 -> 1844738477360
	1844738477504 [label=ConvolutionBackward0]
	1844738477648 -> 1844738477504
	1844738477648 [label=GeluBackward0]
	1844738477840 -> 1844738477648
	1844738477840 [label=ConvolutionBackward0]
	1844738477936 -> 1844738477840
	1844738477936 [label=NativeBatchNormBackward0]
	1844738478128 -> 1844738477936
	1844738478128 [label=CatBackward0]
	1844738478320 -> 1844738478128
	1844738478320 [label=SplitWithSizesBackward0]
	1844738477216 -> 1844738478320
	1844738477216 [label=AddBackward0]
	1844738478608 -> 1844738477216
	1844738478608 [label=MulBackward0]
	1844738478752 -> 1844738478608
	1844738478752 [label=ConvolutionBackward0]
	1844738478896 -> 1844738478752
	1844738478896 [label=GeluBackward0]
	1844738479088 -> 1844738478896
	1844738479088 [label=ConvolutionBackward0]
	1844738479184 -> 1844738479088
	1844738479184 [label=NativeBatchNormBackward0]
	1844738479376 -> 1844738479184
	1844738479376 [label=CatBackward0]
	1844738479568 -> 1844738479376
	1844738479568 [label=SplitWithSizesBackward0]
	1844738478464 -> 1844738479568
	1844738478464 [label=AddBackward0]
	1844738479856 -> 1844738478464
	1844738479856 [label=MulBackward0]
	1844738480000 -> 1844738479856
	1844738480000 [label=ConvolutionBackward0]
	1844738480144 -> 1844738480000
	1844738480144 [label=GeluBackward0]
	1844738480336 -> 1844738480144
	1844738480336 [label=ConvolutionBackward0]
	1844738480432 -> 1844738480336
	1844738480432 [label=NativeBatchNormBackward0]
	1844738480624 -> 1844738480432
	1844738480624 [label=CatBackward0]
	1844738480816 -> 1844738480624
	1844738480816 [label=SplitWithSizesBackward0]
	1844738479712 -> 1844738480816
	1844738479712 [label=AddBackward0]
	1844738481104 -> 1844738479712
	1844738481104 [label=MulBackward0]
	1844738481248 -> 1844738481104
	1844738481248 [label=ConvolutionBackward0]
	1844738481392 -> 1844738481248
	1844738481392 [label=GeluBackward0]
	1844738481584 -> 1844738481392
	1844738481584 [label=ConvolutionBackward0]
	1844738481680 -> 1844738481584
	1844738481680 [label=NativeBatchNormBackward0]
	1844738481872 -> 1844738481680
	1844738481872 [label=CatBackward0]
	1844738482064 -> 1844738481872
	1844738482064 [label=SplitWithSizesBackward0]
	1844738480960 -> 1844738482064
	1844738480960 [label=AddBackward0]
	1844738482352 -> 1844738480960
	1844738482352 [label=MulBackward0]
	1844738482496 -> 1844738482352
	1844738482496 [label=ConvolutionBackward0]
	1844738482640 -> 1844738482496
	1844738482640 [label=GeluBackward0]
	1844738482832 -> 1844738482640
	1844738482832 [label=ConvolutionBackward0]
	1844738482928 -> 1844738482832
	1844738482928 [label=NativeBatchNormBackward0]
	1844738483120 -> 1844738482928
	1844738483120 [label=CatBackward0]
	1844738483312 -> 1844738483120
	1844738483312 [label=SplitWithSizesBackward0]
	1844738482208 -> 1844738483312
	1844738482208 [label=ConvolutionBackward0]
	1844738483600 -> 1844738482208
	1844738483600 [label=NativeBatchNormBackward0]
	1844738483792 -> 1844738483600
	1844738483792 [label=AddBackward0]
	1844738483984 -> 1844738483792
	1844738483984 [label=MulBackward0]
	1844738484176 -> 1844738483984
	1844738484176 [label=ConvolutionBackward0]
	1844738484320 -> 1844738484176
	1844738484320 [label=GeluBackward0]
	1844738484512 -> 1844738484320
	1844738484512 [label=ConvolutionBackward0]
	1844738484608 -> 1844738484512
	1844738484608 [label=NativeBatchNormBackward0]
	1844738484800 -> 1844738484608
	1844738484800 [label=CatBackward0]
	1844738484992 -> 1844738484800
	1844738484992 [label=SplitWithSizesBackward0]
	1844738483936 -> 1844738484992
	1844738483936 [label=AddBackward0]
	1844738485280 -> 1844738483936
	1844738485280 [label=MulBackward0]
	1844738485424 -> 1844738485280
	1844738485424 [label=ConvolutionBackward0]
	1844738485568 -> 1844738485424
	1844738485568 [label=GeluBackward0]
	1844738485760 -> 1844738485568
	1844738485760 [label=ConvolutionBackward0]
	1844738485856 -> 1844738485760
	1844738485856 [label=NativeBatchNormBackward0]
	1844738486048 -> 1844738485856
	1844738486048 [label=CatBackward0]
	1844738486240 -> 1844738486048
	1844738486240 [label=SplitWithSizesBackward0]
	1844738485136 -> 1844738486240
	1844738485136 [label=AddBackward0]
	1844738486528 -> 1844738485136
	1844738486528 [label=MulBackward0]
	1844738486672 -> 1844738486528
	1844738486672 [label=ConvolutionBackward0]
	1844738486816 -> 1844738486672
	1844738486816 [label=GeluBackward0]
	1844738487008 -> 1844738486816
	1844738487008 [label=ConvolutionBackward0]
	1844738487104 -> 1844738487008
	1844738487104 [label=NativeBatchNormBackward0]
	1844738487296 -> 1844738487104
	1844738487296 [label=CatBackward0]
	1844738487488 -> 1844738487296
	1844738487488 [label=SplitWithSizesBackward0]
	1844738486384 -> 1844738487488
	1844738486384 [label=ConvolutionBackward0]
	1844738487776 -> 1844738486384
	1844738487776 [label=NativeBatchNormBackward0]
	1844738487968 -> 1844738487776
	1844738487968 [label=AddBackward0]
	1844738488160 -> 1844738487968
	1844738488160 [label=MulBackward0]
	1844738488304 -> 1844738488160
	1844738488304 [label=ConvolutionBackward0]
	1844738488448 -> 1844738488304
	1844738488448 [label=GeluBackward0]
	1844738488640 -> 1844738488448
	1844738488640 [label=ConvolutionBackward0]
	1844738488736 -> 1844738488640
	1844738488736 [label=NativeBatchNormBackward0]
	1844738488928 -> 1844738488736
	1844738488928 [label=CatBackward0]
	1844738489120 -> 1844738488928
	1844738489120 [label=SplitWithSizesBackward0]
	1844738488112 -> 1844738489120
	1844738488112 [label=AddBackward0]
	1844738489408 -> 1844738488112
	1844738489408 [label=MulBackward0]
	1844738489552 -> 1844738489408
	1844738489552 [label=ConvolutionBackward0]
	1844738489696 -> 1844738489552
	1844738489696 [label=GeluBackward0]
	1844738489888 -> 1844738489696
	1844738489888 [label=ConvolutionBackward0]
	1844738489984 -> 1844738489888
	1844738489984 [label=NativeBatchNormBackward0]
	1844738490176 -> 1844738489984
	1844738490176 [label=CatBackward0]
	1844738490320 -> 1844738490176
	1844738490320 [label=SplitWithSizesBackward0]
	1844738489264 -> 1844738490320
	1844738489264 [label=AddBackward0]
	1844738507104 -> 1844738489264
	1844738507104 [label=MulBackward0]
	1844738507248 -> 1844738507104
	1844738507248 [label=ConvolutionBackward0]
	1844738507392 -> 1844738507248
	1844738507392 [label=GeluBackward0]
	1844738507584 -> 1844738507392
	1844738507584 [label=ConvolutionBackward0]
	1844738507680 -> 1844738507584
	1844738507680 [label=NativeBatchNormBackward0]
	1844738507872 -> 1844738507680
	1844738507872 [label=CatBackward0]
	1844738508064 -> 1844738507872
	1844738508064 [label=SplitWithSizesBackward0]
	1844738506960 -> 1844738508064
	1844738506960 [label=NativeBatchNormBackward0]
	1844738508352 -> 1844738506960
	1844738508352 [label=ConvolutionBackward0]
	1844738508544 -> 1844738508352
	1846263743568 [label="stem.0.weight
 (96, 1, 4, 4)" fillcolor=lightblue]
	1846263743568 -> 1844738508544
	1844738508544 [label=AccumulateGrad]
	1844738508496 -> 1844738508352
	1846165889056 [label="stem.0.bias
 (96)" fillcolor=lightblue]
	1846165889056 -> 1844738508496
	1844738508496 [label=AccumulateGrad]
	1844738508208 -> 1844738506960
	1846137048016 [label="stem.1.weight
 (96)" fillcolor=lightblue]
	1846137048016 -> 1844738508208
	1844738508208 [label=AccumulateGrad]
	1844738508256 -> 1844738506960
	1845551896016 [label="stem.1.bias
 (96)" fillcolor=lightblue]
	1845551896016 -> 1844738508256
	1844738508256 [label=AccumulateGrad]
	1844738508016 -> 1844738507872
	1844738508016 [label=ConvolutionBackward0]
	1844738508064 -> 1844738508016
	1844738508448 -> 1844738508016
	1846158624464 [label="stages.0.blocks.0.token_mixer.dwconv_hw.weight
 (12, 1, 3, 3)" fillcolor=lightblue]
	1846158624464 -> 1844738508448
	1844738508448 [label=AccumulateGrad]
	1844738508400 -> 1844738508016
	1846268753568 [label="stages.0.blocks.0.token_mixer.dwconv_hw.bias
 (12)" fillcolor=lightblue]
	1846268753568 -> 1844738508400
	1844738508400 [label=AccumulateGrad]
	1844738507968 -> 1844738507872
	1844738507968 [label=ConvolutionBackward0]
	1844738508064 -> 1844738507968
	1844738508640 -> 1844738507968
	1845551896416 [label="stages.0.blocks.0.token_mixer.dwconv_w.weight
 (12, 1, 1, 11)" fillcolor=lightblue]
	1845551896416 -> 1844738508640
	1844738508640 [label=AccumulateGrad]
	1844738508592 -> 1844738507968
	1845551896336 [label="stages.0.blocks.0.token_mixer.dwconv_w.bias
 (12)" fillcolor=lightblue]
	1845551896336 -> 1844738508592
	1844738508592 [label=AccumulateGrad]
	1844738508112 -> 1844738507872
	1844738508112 [label=ConvolutionBackward0]
	1844738508064 -> 1844738508112
	1844738508736 -> 1844738508112
	1845551896576 [label="stages.0.blocks.0.token_mixer.dwconv_h.weight
 (12, 1, 11, 1)" fillcolor=lightblue]
	1845551896576 -> 1844738508736
	1844738508736 [label=AccumulateGrad]
	1844738508688 -> 1844738508112
	1845551896656 [label="stages.0.blocks.0.token_mixer.dwconv_h.bias
 (12)" fillcolor=lightblue]
	1845551896656 -> 1844738508688
	1844738508688 [label=AccumulateGrad]
	1844738507824 -> 1844738507680
	1845551896736 [label="stages.0.blocks.0.norm.weight
 (96)" fillcolor=lightblue]
	1845551896736 -> 1844738507824
	1844738507824 [label=AccumulateGrad]
	1844738507776 -> 1844738507680
	1845551896816 [label="stages.0.blocks.0.norm.bias
 (96)" fillcolor=lightblue]
	1845551896816 -> 1844738507776
	1844738507776 [label=AccumulateGrad]
	1844738507632 -> 1844738507584
	1846167684336 [label="stages.0.blocks.0.mlp.fc1.weight
 (384, 96, 1, 1)" fillcolor=lightblue]
	1846167684336 -> 1844738507632
	1844738507632 [label=AccumulateGrad]
	1844738507488 -> 1844738507584
	1846167684416 [label="stages.0.blocks.0.mlp.fc1.bias
 (384)" fillcolor=lightblue]
	1846167684416 -> 1844738507488
	1844738507488 [label=AccumulateGrad]
	1844738507344 -> 1844738507248
	1846167684576 [label="stages.0.blocks.0.mlp.fc2.weight
 (96, 384, 1, 1)" fillcolor=lightblue]
	1846167684576 -> 1844738507344
	1844738507344 [label=AccumulateGrad]
	1844738507296 -> 1844738507248
	1846167684656 [label="stages.0.blocks.0.mlp.fc2.bias
 (96)" fillcolor=lightblue]
	1846167684656 -> 1844738507296
	1844738507296 [label=AccumulateGrad]
	1844738507200 -> 1844738507104
	1844738507200 [label=ReshapeAliasBackward0]
	1844738507728 -> 1844738507200
	1846167684496 [label="stages.0.blocks.0.gamma
 (96)" fillcolor=lightblue]
	1846167684496 -> 1844738507728
	1844738507728 [label=AccumulateGrad]
	1844738506960 -> 1844738489264
	1844738490272 -> 1844738490176
	1844738490272 [label=ConvolutionBackward0]
	1844738490320 -> 1844738490272
	1844738507152 -> 1844738490272
	1846167684896 [label="stages.0.blocks.1.token_mixer.dwconv_hw.weight
 (12, 1, 3, 3)" fillcolor=lightblue]
	1846167684896 -> 1844738507152
	1844738507152 [label=AccumulateGrad]
	1844738507008 -> 1844738490272
	1846167684976 [label="stages.0.blocks.1.token_mixer.dwconv_hw.bias
 (12)" fillcolor=lightblue]
	1846167684976 -> 1844738507008
	1844738507008 [label=AccumulateGrad]
	1844738506816 -> 1844738490176
	1844738506816 [label=ConvolutionBackward0]
	1844738490320 -> 1844738506816
	1844738508160 -> 1844738506816
	1846167685136 [label="stages.0.blocks.1.token_mixer.dwconv_w.weight
 (12, 1, 1, 11)" fillcolor=lightblue]
	1846167685136 -> 1844738508160
	1844738508160 [label=AccumulateGrad]
	1844738507536 -> 1844738506816
	1846167685216 [label="stages.0.blocks.1.token_mixer.dwconv_w.bias
 (12)" fillcolor=lightblue]
	1846167685216 -> 1844738507536
	1844738507536 [label=AccumulateGrad]
	1844738506864 -> 1844738490176
	1844738506864 [label=ConvolutionBackward0]
	1844738490320 -> 1844738506864
	1844738507440 -> 1844738506864
	1846167685376 [label="stages.0.blocks.1.token_mixer.dwconv_h.weight
 (12, 1, 11, 1)" fillcolor=lightblue]
	1846167685376 -> 1844738507440
	1844738507440 [label=AccumulateGrad]
	1844738507920 -> 1844738506864
	1846167685456 [label="stages.0.blocks.1.token_mixer.dwconv_h.bias
 (12)" fillcolor=lightblue]
	1846167685456 -> 1844738507920
	1844738507920 [label=AccumulateGrad]
	1844738490128 -> 1844738489984
	1846167685536 [label="stages.0.blocks.1.norm.weight
 (96)" fillcolor=lightblue]
	1846167685536 -> 1844738490128
	1844738490128 [label=AccumulateGrad]
	1844738490080 -> 1844738489984
	1846167685616 [label="stages.0.blocks.1.norm.bias
 (96)" fillcolor=lightblue]
	1846167685616 -> 1844738490080
	1844738490080 [label=AccumulateGrad]
	1844738489936 -> 1844738489888
	1846167686096 [label="stages.0.blocks.1.mlp.fc1.weight
 (384, 96, 1, 1)" fillcolor=lightblue]
	1846167686096 -> 1844738489936
	1844738489936 [label=AccumulateGrad]
	1844738489792 -> 1844738489888
	1846167686176 [label="stages.0.blocks.1.mlp.fc1.bias
 (384)" fillcolor=lightblue]
	1846167686176 -> 1844738489792
	1844738489792 [label=AccumulateGrad]
	1844738489648 -> 1844738489552
	1846167686336 [label="stages.0.blocks.1.mlp.fc2.weight
 (96, 384, 1, 1)" fillcolor=lightblue]
	1846167686336 -> 1844738489648
	1844738489648 [label=AccumulateGrad]
	1844738489600 -> 1844738489552
	1846167686416 [label="stages.0.blocks.1.mlp.fc2.bias
 (96)" fillcolor=lightblue]
	1846167686416 -> 1844738489600
	1844738489600 [label=AccumulateGrad]
	1844738489504 -> 1844738489408
	1844738489504 [label=ReshapeAliasBackward0]
	1844738490032 -> 1844738489504
	1846167686256 [label="stages.0.blocks.1.gamma
 (96)" fillcolor=lightblue]
	1846167686256 -> 1844738490032
	1844738490032 [label=AccumulateGrad]
	1844738489264 -> 1844738488112
	1844738489072 -> 1844738488928
	1844738489072 [label=ConvolutionBackward0]
	1844738489120 -> 1844738489072
	1844738489456 -> 1844738489072
	1846167686656 [label="stages.0.blocks.2.token_mixer.dwconv_hw.weight
 (12, 1, 3, 3)" fillcolor=lightblue]
	1846167686656 -> 1844738489456
	1844738489456 [label=AccumulateGrad]
	1844738489312 -> 1844738489072
	1846167686736 [label="stages.0.blocks.2.token_mixer.dwconv_hw.bias
 (12)" fillcolor=lightblue]
	1846167686736 -> 1844738489312
	1844738489312 [label=AccumulateGrad]
	1844738489024 -> 1844738488928
	1844738489024 [label=ConvolutionBackward0]
	1844738489120 -> 1844738489024
	1844738490224 -> 1844738489024
	1846167686896 [label="stages.0.blocks.2.token_mixer.dwconv_w.weight
 (12, 1, 1, 11)" fillcolor=lightblue]
	1846167686896 -> 1844738490224
	1844738490224 [label=AccumulateGrad]
	1844738489840 -> 1844738489024
	1846167686976 [label="stages.0.blocks.2.token_mixer.dwconv_w.bias
 (12)" fillcolor=lightblue]
	1846167686976 -> 1844738489840
	1844738489840 [label=AccumulateGrad]
	1844738489168 -> 1844738488928
	1844738489168 [label=ConvolutionBackward0]
	1844738489120 -> 1844738489168
	1844738489744 -> 1844738489168
	1846167687136 [label="stages.0.blocks.2.token_mixer.dwconv_h.weight
 (12, 1, 11, 1)" fillcolor=lightblue]
	1846167687136 -> 1844738489744
	1844738489744 [label=AccumulateGrad]
	1844738489360 -> 1844738489168
	1846167687216 [label="stages.0.blocks.2.token_mixer.dwconv_h.bias
 (12)" fillcolor=lightblue]
	1846167687216 -> 1844738489360
	1844738489360 [label=AccumulateGrad]
	1844738488880 -> 1844738488736
	1846167687296 [label="stages.0.blocks.2.norm.weight
 (96)" fillcolor=lightblue]
	1846167687296 -> 1844738488880
	1844738488880 [label=AccumulateGrad]
	1844738488832 -> 1844738488736
	1846167687376 [label="stages.0.blocks.2.norm.bias
 (96)" fillcolor=lightblue]
	1846167687376 -> 1844738488832
	1844738488832 [label=AccumulateGrad]
	1844738488688 -> 1844738488640
	1846167687856 [label="stages.0.blocks.2.mlp.fc1.weight
 (384, 96, 1, 1)" fillcolor=lightblue]
	1846167687856 -> 1844738488688
	1844738488688 [label=AccumulateGrad]
	1844738488544 -> 1844738488640
	1846167687936 [label="stages.0.blocks.2.mlp.fc1.bias
 (384)" fillcolor=lightblue]
	1846167687936 -> 1844738488544
	1844738488544 [label=AccumulateGrad]
	1844738488400 -> 1844738488304
	1846167688096 [label="stages.0.blocks.2.mlp.fc2.weight
 (96, 384, 1, 1)" fillcolor=lightblue]
	1846167688096 -> 1844738488400
	1844738488400 [label=AccumulateGrad]
	1844738488352 -> 1844738488304
	1846167688176 [label="stages.0.blocks.2.mlp.fc2.bias
 (96)" fillcolor=lightblue]
	1846167688176 -> 1844738488352
	1844738488352 [label=AccumulateGrad]
	1844738488256 -> 1844738488160
	1844738488256 [label=ReshapeAliasBackward0]
	1844738488784 -> 1844738488256
	1846167688016 [label="stages.0.blocks.2.gamma
 (96)" fillcolor=lightblue]
	1846167688016 -> 1844738488784
	1844738488784 [label=AccumulateGrad]
	1844738488112 -> 1844738487968
	1844738487920 -> 1844738487776
	1846167688256 [label="stages.1.downsample.0.weight
 (96)" fillcolor=lightblue]
	1846167688256 -> 1844738487920
	1844738487920 [label=AccumulateGrad]
	1844738487872 -> 1844738487776
	1846167688336 [label="stages.1.downsample.0.bias
 (96)" fillcolor=lightblue]
	1846167688336 -> 1844738487872
	1844738487872 [label=AccumulateGrad]
	1844738487632 -> 1844738486384
	1846167688816 [label="stages.1.downsample.1.weight
 (192, 96, 2, 2)" fillcolor=lightblue]
	1846167688816 -> 1844738487632
	1844738487632 [label=AccumulateGrad]
	1844738487680 -> 1844738486384
	1846167688896 [label="stages.1.downsample.1.bias
 (192)" fillcolor=lightblue]
	1846167688896 -> 1844738487680
	1844738487680 [label=AccumulateGrad]
	1844738487440 -> 1844738487296
	1844738487440 [label=ConvolutionBackward0]
	1844738487488 -> 1844738487440
	1844738488016 -> 1844738487440
	1846167689136 [label="stages.1.blocks.0.token_mixer.dwconv_hw.weight
 (24, 1, 3, 3)" fillcolor=lightblue]
	1846167689136 -> 1844738488016
	1844738488016 [label=AccumulateGrad]
	1844738487824 -> 1844738487440
	1846167689216 [label="stages.1.blocks.0.token_mixer.dwconv_hw.bias
 (24)" fillcolor=lightblue]
	1846167689216 -> 1844738487824
	1844738487824 [label=AccumulateGrad]
	1844738487392 -> 1844738487296
	1844738487392 [label=ConvolutionBackward0]
	1844738487488 -> 1844738487392
	1844738488208 -> 1844738487392
	1846167689376 [label="stages.1.blocks.0.token_mixer.dwconv_w.weight
 (24, 1, 1, 11)" fillcolor=lightblue]
	1846167689376 -> 1844738488208
	1844738488208 [label=AccumulateGrad]
	1844738488064 -> 1844738487392
	1846167689456 [label="stages.1.blocks.0.token_mixer.dwconv_w.bias
 (24)" fillcolor=lightblue]
	1846167689456 -> 1844738488064
	1844738488064 [label=AccumulateGrad]
	1844738487536 -> 1844738487296
	1844738487536 [label=ConvolutionBackward0]
	1844738487488 -> 1844738487536
	1844738489216 -> 1844738487536
	1846167689616 [label="stages.1.blocks.0.token_mixer.dwconv_h.weight
 (24, 1, 11, 1)" fillcolor=lightblue]
	1846167689616 -> 1844738489216
	1844738489216 [label=AccumulateGrad]
	1844738488592 -> 1844738487536
	1846167689696 [label="stages.1.blocks.0.token_mixer.dwconv_h.bias
 (24)" fillcolor=lightblue]
	1846167689696 -> 1844738488592
	1844738488592 [label=AccumulateGrad]
	1844738487248 -> 1844738487104
	1846167689776 [label="stages.1.blocks.0.norm.weight
 (192)" fillcolor=lightblue]
	1846167689776 -> 1844738487248
	1844738487248 [label=AccumulateGrad]
	1844738487200 -> 1844738487104
	1846167689856 [label="stages.1.blocks.0.norm.bias
 (192)" fillcolor=lightblue]
	1846167689856 -> 1844738487200
	1844738487200 [label=AccumulateGrad]
	1844738487056 -> 1844738487008
	1846167690336 [label="stages.1.blocks.0.mlp.fc1.weight
 (768, 192, 1, 1)" fillcolor=lightblue]
	1846167690336 -> 1844738487056
	1844738487056 [label=AccumulateGrad]
	1844738486912 -> 1844738487008
	1846167690416 [label="stages.1.blocks.0.mlp.fc1.bias
 (768)" fillcolor=lightblue]
	1846167690416 -> 1844738486912
	1844738486912 [label=AccumulateGrad]
	1844738486768 -> 1844738486672
	1846167690576 [label="stages.1.blocks.0.mlp.fc2.weight
 (192, 768, 1, 1)" fillcolor=lightblue]
	1846167690576 -> 1844738486768
	1844738486768 [label=AccumulateGrad]
	1844738486720 -> 1844738486672
	1846167690656 [label="stages.1.blocks.0.mlp.fc2.bias
 (192)" fillcolor=lightblue]
	1846167690656 -> 1844738486720
	1844738486720 [label=AccumulateGrad]
	1844738486624 -> 1844738486528
	1844738486624 [label=ReshapeAliasBackward0]
	1844738487152 -> 1844738486624
	1846167690496 [label="stages.1.blocks.0.gamma
 (192)" fillcolor=lightblue]
	1846167690496 -> 1844738487152
	1844738487152 [label=AccumulateGrad]
	1844738486384 -> 1844738485136
	1844738486192 -> 1844738486048
	1844738486192 [label=ConvolutionBackward0]
	1844738486240 -> 1844738486192
	1844738486576 -> 1844738486192
	1846167690896 [label="stages.1.blocks.1.token_mixer.dwconv_hw.weight
 (24, 1, 3, 3)" fillcolor=lightblue]
	1846167690896 -> 1844738486576
	1844738486576 [label=AccumulateGrad]
	1844738486432 -> 1844738486192
	1846167690976 [label="stages.1.blocks.1.token_mixer.dwconv_hw.bias
 (24)" fillcolor=lightblue]
	1846167690976 -> 1844738486432
	1844738486432 [label=AccumulateGrad]
	1844738486144 -> 1844738486048
	1844738486144 [label=ConvolutionBackward0]
	1844738486240 -> 1844738486144
	1844738487584 -> 1844738486144
	1846167691136 [label="stages.1.blocks.1.token_mixer.dwconv_w.weight
 (24, 1, 1, 11)" fillcolor=lightblue]
	1846167691136 -> 1844738487584
	1844738487584 [label=AccumulateGrad]
	1844738486960 -> 1844738486144
	1846167691216 [label="stages.1.blocks.1.token_mixer.dwconv_w.bias
 (24)" fillcolor=lightblue]
	1846167691216 -> 1844738486960
	1844738486960 [label=AccumulateGrad]
	1844738486288 -> 1844738486048
	1844738486288 [label=ConvolutionBackward0]
	1844738486240 -> 1844738486288
	1844738486864 -> 1844738486288
	1846167691376 [label="stages.1.blocks.1.token_mixer.dwconv_h.weight
 (24, 1, 11, 1)" fillcolor=lightblue]
	1846167691376 -> 1844738486864
	1844738486864 [label=AccumulateGrad]
	1844738487344 -> 1844738486288
	1846167691456 [label="stages.1.blocks.1.token_mixer.dwconv_h.bias
 (24)" fillcolor=lightblue]
	1846167691456 -> 1844738487344
	1844738487344 [label=AccumulateGrad]
	1844738486000 -> 1844738485856
	1846167691536 [label="stages.1.blocks.1.norm.weight
 (192)" fillcolor=lightblue]
	1846167691536 -> 1844738486000
	1844738486000 [label=AccumulateGrad]
	1844738485952 -> 1844738485856
	1846167691616 [label="stages.1.blocks.1.norm.bias
 (192)" fillcolor=lightblue]
	1846167691616 -> 1844738485952
	1844738485952 [label=AccumulateGrad]
	1844738485808 -> 1844738485760
	1846167692096 [label="stages.1.blocks.1.mlp.fc1.weight
 (768, 192, 1, 1)" fillcolor=lightblue]
	1846167692096 -> 1844738485808
	1844738485808 [label=AccumulateGrad]
	1844738485664 -> 1844738485760
	1846167692176 [label="stages.1.blocks.1.mlp.fc1.bias
 (768)" fillcolor=lightblue]
	1846167692176 -> 1844738485664
	1844738485664 [label=AccumulateGrad]
	1844738485520 -> 1844738485424
	1846167692336 [label="stages.1.blocks.1.mlp.fc2.weight
 (192, 768, 1, 1)" fillcolor=lightblue]
	1846167692336 -> 1844738485520
	1844738485520 [label=AccumulateGrad]
	1844738485472 -> 1844738485424
	1846167692416 [label="stages.1.blocks.1.mlp.fc2.bias
 (192)" fillcolor=lightblue]
	1846167692416 -> 1844738485472
	1844738485472 [label=AccumulateGrad]
	1844738485376 -> 1844738485280
	1844738485376 [label=ReshapeAliasBackward0]
	1844738485904 -> 1844738485376
	1846167692256 [label="stages.1.blocks.1.gamma
 (192)" fillcolor=lightblue]
	1846167692256 -> 1844738485904
	1844738485904 [label=AccumulateGrad]
	1844738485136 -> 1844738483936
	1844738484944 -> 1844738484800
	1844738484944 [label=ConvolutionBackward0]
	1844738484992 -> 1844738484944
	1844738485328 -> 1844738484944
	1846167692656 [label="stages.1.blocks.2.token_mixer.dwconv_hw.weight
 (24, 1, 3, 3)" fillcolor=lightblue]
	1846167692656 -> 1844738485328
	1844738485328 [label=AccumulateGrad]
	1844738485184 -> 1844738484944
	1846167692736 [label="stages.1.blocks.2.token_mixer.dwconv_hw.bias
 (24)" fillcolor=lightblue]
	1846167692736 -> 1844738485184
	1844738485184 [label=AccumulateGrad]
	1844738484896 -> 1844738484800
	1844738484896 [label=ConvolutionBackward0]
	1844738484992 -> 1844738484896
	1844738486336 -> 1844738484896
	1846167692896 [label="stages.1.blocks.2.token_mixer.dwconv_w.weight
 (24, 1, 1, 11)" fillcolor=lightblue]
	1846167692896 -> 1844738486336
	1844738486336 [label=AccumulateGrad]
	1844738485712 -> 1844738484896
	1846167692976 [label="stages.1.blocks.2.token_mixer.dwconv_w.bias
 (24)" fillcolor=lightblue]
	1846167692976 -> 1844738485712
	1844738485712 [label=AccumulateGrad]
	1844738485040 -> 1844738484800
	1844738485040 [label=ConvolutionBackward0]
	1844738484992 -> 1844738485040
	1844738485616 -> 1844738485040
	1846167693136 [label="stages.1.blocks.2.token_mixer.dwconv_h.weight
 (24, 1, 11, 1)" fillcolor=lightblue]
	1846167693136 -> 1844738485616
	1844738485616 [label=AccumulateGrad]
	1844738486096 -> 1844738485040
	1846167693216 [label="stages.1.blocks.2.token_mixer.dwconv_h.bias
 (24)" fillcolor=lightblue]
	1846167693216 -> 1844738486096
	1844738486096 [label=AccumulateGrad]
	1844738484752 -> 1844738484608
	1846167693296 [label="stages.1.blocks.2.norm.weight
 (192)" fillcolor=lightblue]
	1846167693296 -> 1844738484752
	1844738484752 [label=AccumulateGrad]
	1844738484704 -> 1844738484608
	1846167693376 [label="stages.1.blocks.2.norm.bias
 (192)" fillcolor=lightblue]
	1846167693376 -> 1844738484704
	1844738484704 [label=AccumulateGrad]
	1844738484560 -> 1844738484512
	1846167693856 [label="stages.1.blocks.2.mlp.fc1.weight
 (768, 192, 1, 1)" fillcolor=lightblue]
	1846167693856 -> 1844738484560
	1844738484560 [label=AccumulateGrad]
	1844738484416 -> 1844738484512
	1846167693936 [label="stages.1.blocks.2.mlp.fc1.bias
 (768)" fillcolor=lightblue]
	1846167693936 -> 1844738484416
	1844738484416 [label=AccumulateGrad]
	1844738484272 -> 1844738484176
	1846167694096 [label="stages.1.blocks.2.mlp.fc2.weight
 (192, 768, 1, 1)" fillcolor=lightblue]
	1846167694096 -> 1844738484272
	1844738484272 [label=AccumulateGrad]
	1844738484224 -> 1844738484176
	1846167694176 [label="stages.1.blocks.2.mlp.fc2.bias
 (192)" fillcolor=lightblue]
	1846167694176 -> 1844738484224
	1844738484224 [label=AccumulateGrad]
	1844738484128 -> 1844738483984
	1844738484128 [label=ReshapeAliasBackward0]
	1844738484656 -> 1844738484128
	1846167694016 [label="stages.1.blocks.2.gamma
 (192)" fillcolor=lightblue]
	1846167694016 -> 1844738484656
	1844738484656 [label=AccumulateGrad]
	1844738483936 -> 1844738483792
	1844738483744 -> 1844738483600
	1846167694256 [label="stages.2.downsample.0.weight
 (192)" fillcolor=lightblue]
	1846167694256 -> 1844738483744
	1844738483744 [label=AccumulateGrad]
	1844738483696 -> 1844738483600
	1846167694336 [label="stages.2.downsample.0.bias
 (192)" fillcolor=lightblue]
	1846167694336 -> 1844738483696
	1844738483696 [label=AccumulateGrad]
	1844738483456 -> 1844738482208
	1846167694816 [label="stages.2.downsample.1.weight
 (384, 192, 2, 2)" fillcolor=lightblue]
	1846167694816 -> 1844738483456
	1844738483456 [label=AccumulateGrad]
	1844738483504 -> 1844738482208
	1846167694896 [label="stages.2.downsample.1.bias
 (384)" fillcolor=lightblue]
	1846167694896 -> 1844738483504
	1844738483504 [label=AccumulateGrad]
	1844738483264 -> 1844738483120
	1844738483264 [label=ConvolutionBackward0]
	1844738483312 -> 1844738483264
	1844738483840 -> 1844738483264
	1846167695136 [label="stages.2.blocks.0.token_mixer.dwconv_hw.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	1846167695136 -> 1844738483840
	1844738483840 [label=AccumulateGrad]
	1844738483648 -> 1844738483264
	1846167695216 [label="stages.2.blocks.0.token_mixer.dwconv_hw.bias
 (48)" fillcolor=lightblue]
	1846167695216 -> 1844738483648
	1844738483648 [label=AccumulateGrad]
	1844738483216 -> 1844738483120
	1844738483216 [label=ConvolutionBackward0]
	1844738483312 -> 1844738483216
	1844738484080 -> 1844738483216
	1846167695376 [label="stages.2.blocks.0.token_mixer.dwconv_w.weight
 (48, 1, 1, 11)" fillcolor=lightblue]
	1846167695376 -> 1844738484080
	1844738484080 [label=AccumulateGrad]
	1844738483888 -> 1844738483216
	1846167695456 [label="stages.2.blocks.0.token_mixer.dwconv_w.bias
 (48)" fillcolor=lightblue]
	1846167695456 -> 1844738483888
	1844738483888 [label=AccumulateGrad]
	1844738483360 -> 1844738483120
	1844738483360 [label=ConvolutionBackward0]
	1844738483312 -> 1844738483360
	1844738487728 -> 1844738483360
	1846167695616 [label="stages.2.blocks.0.token_mixer.dwconv_h.weight
 (48, 1, 11, 1)" fillcolor=lightblue]
	1846167695616 -> 1844738487728
	1844738487728 [label=AccumulateGrad]
	1844738484464 -> 1844738483360
	1846167695696 [label="stages.2.blocks.0.token_mixer.dwconv_h.bias
 (48)" fillcolor=lightblue]
	1846167695696 -> 1844738484464
	1844738484464 [label=AccumulateGrad]
	1844738483072 -> 1844738482928
	1846167695776 [label="stages.2.blocks.0.norm.weight
 (384)" fillcolor=lightblue]
	1846167695776 -> 1844738483072
	1844738483072 [label=AccumulateGrad]
	1844738483024 -> 1844738482928
	1846167695856 [label="stages.2.blocks.0.norm.bias
 (384)" fillcolor=lightblue]
	1846167695856 -> 1844738483024
	1844738483024 [label=AccumulateGrad]
	1844738482880 -> 1844738482832
	1846167696336 [label="stages.2.blocks.0.mlp.fc1.weight
 (1536, 384, 1, 1)" fillcolor=lightblue]
	1846167696336 -> 1844738482880
	1844738482880 [label=AccumulateGrad]
	1844738482736 -> 1844738482832
	1846167696416 [label="stages.2.blocks.0.mlp.fc1.bias
 (1536)" fillcolor=lightblue]
	1846167696416 -> 1844738482736
	1844738482736 [label=AccumulateGrad]
	1844738482592 -> 1844738482496
	1846167696576 [label="stages.2.blocks.0.mlp.fc2.weight
 (384, 1536, 1, 1)" fillcolor=lightblue]
	1846167696576 -> 1844738482592
	1844738482592 [label=AccumulateGrad]
	1844738482544 -> 1844738482496
	1846167696656 [label="stages.2.blocks.0.mlp.fc2.bias
 (384)" fillcolor=lightblue]
	1846167696656 -> 1844738482544
	1844738482544 [label=AccumulateGrad]
	1844738482448 -> 1844738482352
	1844738482448 [label=ReshapeAliasBackward0]
	1844738482976 -> 1844738482448
	1846167696496 [label="stages.2.blocks.0.gamma
 (384)" fillcolor=lightblue]
	1846167696496 -> 1844738482976
	1844738482976 [label=AccumulateGrad]
	1844738482208 -> 1844738480960
	1844738482016 -> 1844738481872
	1844738482016 [label=ConvolutionBackward0]
	1844738482064 -> 1844738482016
	1844738482400 -> 1844738482016
	1846167696896 [label="stages.2.blocks.1.token_mixer.dwconv_hw.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	1846167696896 -> 1844738482400
	1844738482400 [label=AccumulateGrad]
	1844738482256 -> 1844738482016
	1846167696976 [label="stages.2.blocks.1.token_mixer.dwconv_hw.bias
 (48)" fillcolor=lightblue]
	1846167696976 -> 1844738482256
	1844738482256 [label=AccumulateGrad]
	1844738481968 -> 1844738481872
	1844738481968 [label=ConvolutionBackward0]
	1844738482064 -> 1844738481968
	1844738483408 -> 1844738481968
	1846167697136 [label="stages.2.blocks.1.token_mixer.dwconv_w.weight
 (48, 1, 1, 11)" fillcolor=lightblue]
	1846167697136 -> 1844738483408
	1844738483408 [label=AccumulateGrad]
	1844738482784 -> 1844738481968
	1846167697216 [label="stages.2.blocks.1.token_mixer.dwconv_w.bias
 (48)" fillcolor=lightblue]
	1846167697216 -> 1844738482784
	1844738482784 [label=AccumulateGrad]
	1844738482112 -> 1844738481872
	1844738482112 [label=ConvolutionBackward0]
	1844738482064 -> 1844738482112
	1844738482688 -> 1844738482112
	1846167697376 [label="stages.2.blocks.1.token_mixer.dwconv_h.weight
 (48, 1, 11, 1)" fillcolor=lightblue]
	1846167697376 -> 1844738482688
	1844738482688 [label=AccumulateGrad]
	1844738483168 -> 1844738482112
	1846167697456 [label="stages.2.blocks.1.token_mixer.dwconv_h.bias
 (48)" fillcolor=lightblue]
	1846167697456 -> 1844738483168
	1844738483168 [label=AccumulateGrad]
	1844738481824 -> 1844738481680
	1846167697616 [label="stages.2.blocks.1.norm.weight
 (384)" fillcolor=lightblue]
	1846167697616 -> 1844738481824
	1844738481824 [label=AccumulateGrad]
	1844738481776 -> 1844738481680
	1846167697696 [label="stages.2.blocks.1.norm.bias
 (384)" fillcolor=lightblue]
	1846167697696 -> 1844738481776
	1844738481776 [label=AccumulateGrad]
	1844738481632 -> 1844738481584
	1846167698176 [label="stages.2.blocks.1.mlp.fc1.weight
 (1536, 384, 1, 1)" fillcolor=lightblue]
	1846167698176 -> 1844738481632
	1844738481632 [label=AccumulateGrad]
	1844738481488 -> 1844738481584
	1846167698256 [label="stages.2.blocks.1.mlp.fc1.bias
 (1536)" fillcolor=lightblue]
	1846167698256 -> 1844738481488
	1844738481488 [label=AccumulateGrad]
	1844738481344 -> 1844738481248
	1846167698416 [label="stages.2.blocks.1.mlp.fc2.weight
 (384, 1536, 1, 1)" fillcolor=lightblue]
	1846167698416 -> 1844738481344
	1844738481344 [label=AccumulateGrad]
	1844738481296 -> 1844738481248
	1846167698496 [label="stages.2.blocks.1.mlp.fc2.bias
 (384)" fillcolor=lightblue]
	1846167698496 -> 1844738481296
	1844738481296 [label=AccumulateGrad]
	1844738481200 -> 1844738481104
	1844738481200 [label=ReshapeAliasBackward0]
	1844738481728 -> 1844738481200
	1846167698336 [label="stages.2.blocks.1.gamma
 (384)" fillcolor=lightblue]
	1846167698336 -> 1844738481728
	1844738481728 [label=AccumulateGrad]
	1844738480960 -> 1844738479712
	1844738480768 -> 1844738480624
	1844738480768 [label=ConvolutionBackward0]
	1844738480816 -> 1844738480768
	1844738481152 -> 1844738480768
	1846167698736 [label="stages.2.blocks.2.token_mixer.dwconv_hw.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	1846167698736 -> 1844738481152
	1844738481152 [label=AccumulateGrad]
	1844738481008 -> 1844738480768
	1846167698816 [label="stages.2.blocks.2.token_mixer.dwconv_hw.bias
 (48)" fillcolor=lightblue]
	1846167698816 -> 1844738481008
	1844738481008 [label=AccumulateGrad]
	1844738480720 -> 1844738480624
	1844738480720 [label=ConvolutionBackward0]
	1844738480816 -> 1844738480720
	1844738482160 -> 1844738480720
	1846167698976 [label="stages.2.blocks.2.token_mixer.dwconv_w.weight
 (48, 1, 1, 11)" fillcolor=lightblue]
	1846167698976 -> 1844738482160
	1844738482160 [label=AccumulateGrad]
	1844738481536 -> 1844738480720
	1846167699056 [label="stages.2.blocks.2.token_mixer.dwconv_w.bias
 (48)" fillcolor=lightblue]
	1846167699056 -> 1844738481536
	1844738481536 [label=AccumulateGrad]
	1844738480864 -> 1844738480624
	1844738480864 [label=ConvolutionBackward0]
	1844738480816 -> 1844738480864
	1844738481440 -> 1844738480864
	1846167699216 [label="stages.2.blocks.2.token_mixer.dwconv_h.weight
 (48, 1, 11, 1)" fillcolor=lightblue]
	1846167699216 -> 1844738481440
	1844738481440 [label=AccumulateGrad]
	1844738481920 -> 1844738480864
	1846167699296 [label="stages.2.blocks.2.token_mixer.dwconv_h.bias
 (48)" fillcolor=lightblue]
	1846167699296 -> 1844738481920
	1844738481920 [label=AccumulateGrad]
	1844738480576 -> 1844738480432
	1845552218176 [label="stages.2.blocks.2.norm.weight
 (384)" fillcolor=lightblue]
	1845552218176 -> 1844738480576
	1844738480576 [label=AccumulateGrad]
	1844738480528 -> 1844738480432
	1845552218256 [label="stages.2.blocks.2.norm.bias
 (384)" fillcolor=lightblue]
	1845552218256 -> 1844738480528
	1844738480528 [label=AccumulateGrad]
	1844738480384 -> 1844738480336
	1845552218736 [label="stages.2.blocks.2.mlp.fc1.weight
 (1536, 384, 1, 1)" fillcolor=lightblue]
	1845552218736 -> 1844738480384
	1844738480384 [label=AccumulateGrad]
	1844738480240 -> 1844738480336
	1845552218816 [label="stages.2.blocks.2.mlp.fc1.bias
 (1536)" fillcolor=lightblue]
	1845552218816 -> 1844738480240
	1844738480240 [label=AccumulateGrad]
	1844738480096 -> 1844738480000
	1845552218976 [label="stages.2.blocks.2.mlp.fc2.weight
 (384, 1536, 1, 1)" fillcolor=lightblue]
	1845552218976 -> 1844738480096
	1844738480096 [label=AccumulateGrad]
	1844738480048 -> 1844738480000
	1845552219056 [label="stages.2.blocks.2.mlp.fc2.bias
 (384)" fillcolor=lightblue]
	1845552219056 -> 1844738480048
	1844738480048 [label=AccumulateGrad]
	1844738479952 -> 1844738479856
	1844738479952 [label=ReshapeAliasBackward0]
	1844738480480 -> 1844738479952
	1845552218896 [label="stages.2.blocks.2.gamma
 (384)" fillcolor=lightblue]
	1845552218896 -> 1844738480480
	1844738480480 [label=AccumulateGrad]
	1844738479712 -> 1844738478464
	1844738479520 -> 1844738479376
	1844738479520 [label=ConvolutionBackward0]
	1844738479568 -> 1844738479520
	1844738479904 -> 1844738479520
	1845552219296 [label="stages.2.blocks.3.token_mixer.dwconv_hw.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	1845552219296 -> 1844738479904
	1844738479904 [label=AccumulateGrad]
	1844738479760 -> 1844738479520
	1845552219376 [label="stages.2.blocks.3.token_mixer.dwconv_hw.bias
 (48)" fillcolor=lightblue]
	1845552219376 -> 1844738479760
	1844738479760 [label=AccumulateGrad]
	1844738479472 -> 1844738479376
	1844738479472 [label=ConvolutionBackward0]
	1844738479568 -> 1844738479472
	1844738480912 -> 1844738479472
	1845552219536 [label="stages.2.blocks.3.token_mixer.dwconv_w.weight
 (48, 1, 1, 11)" fillcolor=lightblue]
	1845552219536 -> 1844738480912
	1844738480912 [label=AccumulateGrad]
	1844738480288 -> 1844738479472
	1845552219616 [label="stages.2.blocks.3.token_mixer.dwconv_w.bias
 (48)" fillcolor=lightblue]
	1845552219616 -> 1844738480288
	1844738480288 [label=AccumulateGrad]
	1844738479616 -> 1844738479376
	1844738479616 [label=ConvolutionBackward0]
	1844738479568 -> 1844738479616
	1844738480192 -> 1844738479616
	1845552219776 [label="stages.2.blocks.3.token_mixer.dwconv_h.weight
 (48, 1, 11, 1)" fillcolor=lightblue]
	1845552219776 -> 1844738480192
	1844738480192 [label=AccumulateGrad]
	1844738480672 -> 1844738479616
	1845552219856 [label="stages.2.blocks.3.token_mixer.dwconv_h.bias
 (48)" fillcolor=lightblue]
	1845552219856 -> 1844738480672
	1844738480672 [label=AccumulateGrad]
	1844738479328 -> 1844738479184
	1845552220016 [label="stages.2.blocks.3.norm.weight
 (384)" fillcolor=lightblue]
	1845552220016 -> 1844738479328
	1844738479328 [label=AccumulateGrad]
	1844738479280 -> 1844738479184
	1845552220096 [label="stages.2.blocks.3.norm.bias
 (384)" fillcolor=lightblue]
	1845552220096 -> 1844738479280
	1844738479280 [label=AccumulateGrad]
	1844738479136 -> 1844738479088
	1845552220576 [label="stages.2.blocks.3.mlp.fc1.weight
 (1536, 384, 1, 1)" fillcolor=lightblue]
	1845552220576 -> 1844738479136
	1844738479136 [label=AccumulateGrad]
	1844738478992 -> 1844738479088
	1845552220656 [label="stages.2.blocks.3.mlp.fc1.bias
 (1536)" fillcolor=lightblue]
	1845552220656 -> 1844738478992
	1844738478992 [label=AccumulateGrad]
	1844738478848 -> 1844738478752
	1845552220736 [label="stages.2.blocks.3.mlp.fc2.weight
 (384, 1536, 1, 1)" fillcolor=lightblue]
	1845552220736 -> 1844738478848
	1844738478848 [label=AccumulateGrad]
	1844738478800 -> 1844738478752
	1845552220816 [label="stages.2.blocks.3.mlp.fc2.bias
 (384)" fillcolor=lightblue]
	1845552220816 -> 1844738478800
	1844738478800 [label=AccumulateGrad]
	1844738478704 -> 1844738478608
	1844738478704 [label=ReshapeAliasBackward0]
	1844738479232 -> 1844738478704
	1845552220496 [label="stages.2.blocks.3.gamma
 (384)" fillcolor=lightblue]
	1845552220496 -> 1844738479232
	1844738479232 [label=AccumulateGrad]
	1844738478464 -> 1844738477216
	1844738478272 -> 1844738478128
	1844738478272 [label=ConvolutionBackward0]
	1844738478320 -> 1844738478272
	1844738478656 -> 1844738478272
	1845552221056 [label="stages.2.blocks.4.token_mixer.dwconv_hw.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	1845552221056 -> 1844738478656
	1844738478656 [label=AccumulateGrad]
	1844738478512 -> 1844738478272
	1845552221136 [label="stages.2.blocks.4.token_mixer.dwconv_hw.bias
 (48)" fillcolor=lightblue]
	1845552221136 -> 1844738478512
	1844738478512 [label=AccumulateGrad]
	1844738478224 -> 1844738478128
	1844738478224 [label=ConvolutionBackward0]
	1844738478320 -> 1844738478224
	1844738479664 -> 1844738478224
	1845552221296 [label="stages.2.blocks.4.token_mixer.dwconv_w.weight
 (48, 1, 1, 11)" fillcolor=lightblue]
	1845552221296 -> 1844738479664
	1844738479664 [label=AccumulateGrad]
	1844738479040 -> 1844738478224
	1845552221376 [label="stages.2.blocks.4.token_mixer.dwconv_w.bias
 (48)" fillcolor=lightblue]
	1845552221376 -> 1844738479040
	1844738479040 [label=AccumulateGrad]
	1844738478368 -> 1844738478128
	1844738478368 [label=ConvolutionBackward0]
	1844738478320 -> 1844738478368
	1844738478944 -> 1844738478368
	1845552221536 [label="stages.2.blocks.4.token_mixer.dwconv_h.weight
 (48, 1, 11, 1)" fillcolor=lightblue]
	1845552221536 -> 1844738478944
	1844738478944 [label=AccumulateGrad]
	1844738479424 -> 1844738478368
	1845552221616 [label="stages.2.blocks.4.token_mixer.dwconv_h.bias
 (48)" fillcolor=lightblue]
	1845552221616 -> 1844738479424
	1844738479424 [label=AccumulateGrad]
	1844738478080 -> 1844738477936
	1845552221776 [label="stages.2.blocks.4.norm.weight
 (384)" fillcolor=lightblue]
	1845552221776 -> 1844738478080
	1844738478080 [label=AccumulateGrad]
	1844738478032 -> 1844738477936
	1845552221856 [label="stages.2.blocks.4.norm.bias
 (384)" fillcolor=lightblue]
	1845552221856 -> 1844738478032
	1844738478032 [label=AccumulateGrad]
	1844738477888 -> 1844738477840
	1845552222336 [label="stages.2.blocks.4.mlp.fc1.weight
 (1536, 384, 1, 1)" fillcolor=lightblue]
	1845552222336 -> 1844738477888
	1844738477888 [label=AccumulateGrad]
	1844738477744 -> 1844738477840
	1845552222416 [label="stages.2.blocks.4.mlp.fc1.bias
 (1536)" fillcolor=lightblue]
	1845552222416 -> 1844738477744
	1844738477744 [label=AccumulateGrad]
	1844738477600 -> 1844738477504
	1845552222576 [label="stages.2.blocks.4.mlp.fc2.weight
 (384, 1536, 1, 1)" fillcolor=lightblue]
	1845552222576 -> 1844738477600
	1844738477600 [label=AccumulateGrad]
	1844738477552 -> 1844738477504
	1845552222656 [label="stages.2.blocks.4.mlp.fc2.bias
 (384)" fillcolor=lightblue]
	1845552222656 -> 1844738477552
	1844738477552 [label=AccumulateGrad]
	1844738477456 -> 1844738477360
	1844738477456 [label=ReshapeAliasBackward0]
	1844738477984 -> 1844738477456
	1845552222496 [label="stages.2.blocks.4.gamma
 (384)" fillcolor=lightblue]
	1845552222496 -> 1844738477984
	1844738477984 [label=AccumulateGrad]
	1844738477216 -> 1844738475968
	1844738477024 -> 1844738476880
	1844738477024 [label=ConvolutionBackward0]
	1844738477072 -> 1844738477024
	1844738477408 -> 1844738477024
	1845552222896 [label="stages.2.blocks.5.token_mixer.dwconv_hw.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	1845552222896 -> 1844738477408
	1844738477408 [label=AccumulateGrad]
	1844738477264 -> 1844738477024
	1845552222976 [label="stages.2.blocks.5.token_mixer.dwconv_hw.bias
 (48)" fillcolor=lightblue]
	1845552222976 -> 1844738477264
	1844738477264 [label=AccumulateGrad]
	1844738476976 -> 1844738476880
	1844738476976 [label=ConvolutionBackward0]
	1844738477072 -> 1844738476976
	1844738478416 -> 1844738476976
	1845552223136 [label="stages.2.blocks.5.token_mixer.dwconv_w.weight
 (48, 1, 1, 11)" fillcolor=lightblue]
	1845552223136 -> 1844738478416
	1844738478416 [label=AccumulateGrad]
	1844738477792 -> 1844738476976
	1845552223216 [label="stages.2.blocks.5.token_mixer.dwconv_w.bias
 (48)" fillcolor=lightblue]
	1845552223216 -> 1844738477792
	1844738477792 [label=AccumulateGrad]
	1844738477120 -> 1844738476880
	1844738477120 [label=ConvolutionBackward0]
	1844738477072 -> 1844738477120
	1844738477696 -> 1844738477120
	1845552223376 [label="stages.2.blocks.5.token_mixer.dwconv_h.weight
 (48, 1, 11, 1)" fillcolor=lightblue]
	1845552223376 -> 1844738477696
	1844738477696 [label=AccumulateGrad]
	1844738478176 -> 1844738477120
	1845552223456 [label="stages.2.blocks.5.token_mixer.dwconv_h.bias
 (48)" fillcolor=lightblue]
	1845552223456 -> 1844738478176
	1844738478176 [label=AccumulateGrad]
	1844738476832 -> 1844738476688
	1845552223616 [label="stages.2.blocks.5.norm.weight
 (384)" fillcolor=lightblue]
	1845552223616 -> 1844738476832
	1844738476832 [label=AccumulateGrad]
	1844738476784 -> 1844738476688
	1845552223696 [label="stages.2.blocks.5.norm.bias
 (384)" fillcolor=lightblue]
	1845552223696 -> 1844738476784
	1844738476784 [label=AccumulateGrad]
	1844738476640 -> 1844738476592
	1845552224096 [label="stages.2.blocks.5.mlp.fc1.weight
 (1536, 384, 1, 1)" fillcolor=lightblue]
	1845552224096 -> 1844738476640
	1844738476640 [label=AccumulateGrad]
	1844738476496 -> 1844738476592
	1845552224176 [label="stages.2.blocks.5.mlp.fc1.bias
 (1536)" fillcolor=lightblue]
	1845552224176 -> 1844738476496
	1844738476496 [label=AccumulateGrad]
	1844738476352 -> 1844738476256
	1845552224336 [label="stages.2.blocks.5.mlp.fc2.weight
 (384, 1536, 1, 1)" fillcolor=lightblue]
	1845552224336 -> 1844738476352
	1844738476352 [label=AccumulateGrad]
	1844738476304 -> 1844738476256
	1845552224416 [label="stages.2.blocks.5.mlp.fc2.bias
 (384)" fillcolor=lightblue]
	1845552224416 -> 1844738476304
	1844738476304 [label=AccumulateGrad]
	1844738476208 -> 1844738476112
	1844738476208 [label=ReshapeAliasBackward0]
	1844738476736 -> 1844738476208
	1845552224256 [label="stages.2.blocks.5.gamma
 (384)" fillcolor=lightblue]
	1845552224256 -> 1844738476736
	1844738476736 [label=AccumulateGrad]
	1844738475968 -> 1844738474720
	1844738475776 -> 1844738475632
	1844738475776 [label=ConvolutionBackward0]
	1844738475824 -> 1844738475776
	1844738476160 -> 1844738475776
	1845552224656 [label="stages.2.blocks.6.token_mixer.dwconv_hw.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	1845552224656 -> 1844738476160
	1844738476160 [label=AccumulateGrad]
	1844738476016 -> 1844738475776
	1845552224736 [label="stages.2.blocks.6.token_mixer.dwconv_hw.bias
 (48)" fillcolor=lightblue]
	1845552224736 -> 1844738476016
	1844738476016 [label=AccumulateGrad]
	1844738475728 -> 1844738475632
	1844738475728 [label=ConvolutionBackward0]
	1844738475824 -> 1844738475728
	1844738477168 -> 1844738475728
	1845552224896 [label="stages.2.blocks.6.token_mixer.dwconv_w.weight
 (48, 1, 1, 11)" fillcolor=lightblue]
	1845552224896 -> 1844738477168
	1844738477168 [label=AccumulateGrad]
	1844738476544 -> 1844738475728
	1845552224976 [label="stages.2.blocks.6.token_mixer.dwconv_w.bias
 (48)" fillcolor=lightblue]
	1845552224976 -> 1844738476544
	1844738476544 [label=AccumulateGrad]
	1844738475872 -> 1844738475632
	1844738475872 [label=ConvolutionBackward0]
	1844738475824 -> 1844738475872
	1844738476448 -> 1844738475872
	1845552225136 [label="stages.2.blocks.6.token_mixer.dwconv_h.weight
 (48, 1, 11, 1)" fillcolor=lightblue]
	1845552225136 -> 1844738476448
	1844738476448 [label=AccumulateGrad]
	1844738476928 -> 1844738475872
	1845552225216 [label="stages.2.blocks.6.token_mixer.dwconv_h.bias
 (48)" fillcolor=lightblue]
	1845552225216 -> 1844738476928
	1844738476928 [label=AccumulateGrad]
	1844738475584 -> 1844738475440
	1845552225376 [label="stages.2.blocks.6.norm.weight
 (384)" fillcolor=lightblue]
	1845552225376 -> 1844738475584
	1844738475584 [label=AccumulateGrad]
	1844738475536 -> 1844738475440
	1845552225456 [label="stages.2.blocks.6.norm.bias
 (384)" fillcolor=lightblue]
	1845552225456 -> 1844738475536
	1844738475536 [label=AccumulateGrad]
	1844738475392 -> 1844738475344
	1845552225936 [label="stages.2.blocks.6.mlp.fc1.weight
 (1536, 384, 1, 1)" fillcolor=lightblue]
	1845552225936 -> 1844738475392
	1844738475392 [label=AccumulateGrad]
	1844738475248 -> 1844738475344
	1845552226016 [label="stages.2.blocks.6.mlp.fc1.bias
 (1536)" fillcolor=lightblue]
	1845552226016 -> 1844738475248
	1844738475248 [label=AccumulateGrad]
	1844738475104 -> 1844738475008
	1845552226176 [label="stages.2.blocks.6.mlp.fc2.weight
 (384, 1536, 1, 1)" fillcolor=lightblue]
	1845552226176 -> 1844738475104
	1844738475104 [label=AccumulateGrad]
	1844738475056 -> 1844738475008
	1845552226256 [label="stages.2.blocks.6.mlp.fc2.bias
 (384)" fillcolor=lightblue]
	1845552226256 -> 1844738475056
	1844738475056 [label=AccumulateGrad]
	1844738474960 -> 1844738474864
	1844738474960 [label=ReshapeAliasBackward0]
	1844738475488 -> 1844738474960
	1845552226096 [label="stages.2.blocks.6.gamma
 (384)" fillcolor=lightblue]
	1845552226096 -> 1844738475488
	1844738475488 [label=AccumulateGrad]
	1844738474720 -> 1844708572608
	1844738474528 -> 1844738474384
	1844738474528 [label=ConvolutionBackward0]
	1844738474576 -> 1844738474528
	1844738474912 -> 1844738474528
	1845552226496 [label="stages.2.blocks.7.token_mixer.dwconv_hw.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	1845552226496 -> 1844738474912
	1844738474912 [label=AccumulateGrad]
	1844738474768 -> 1844738474528
	1845552226576 [label="stages.2.blocks.7.token_mixer.dwconv_hw.bias
 (48)" fillcolor=lightblue]
	1845552226576 -> 1844738474768
	1844738474768 [label=AccumulateGrad]
	1844738474480 -> 1844738474384
	1844738474480 [label=ConvolutionBackward0]
	1844738474576 -> 1844738474480
	1844738475920 -> 1844738474480
	1845552226736 [label="stages.2.blocks.7.token_mixer.dwconv_w.weight
 (48, 1, 1, 11)" fillcolor=lightblue]
	1845552226736 -> 1844738475920
	1844738475920 [label=AccumulateGrad]
	1844738475296 -> 1844738474480
	1845552226816 [label="stages.2.blocks.7.token_mixer.dwconv_w.bias
 (48)" fillcolor=lightblue]
	1845552226816 -> 1844738475296
	1844738475296 [label=AccumulateGrad]
	1844738474624 -> 1844738474384
	1844738474624 [label=ConvolutionBackward0]
	1844738474576 -> 1844738474624
	1844738475200 -> 1844738474624
	1845552226976 [label="stages.2.blocks.7.token_mixer.dwconv_h.weight
 (48, 1, 11, 1)" fillcolor=lightblue]
	1845552226976 -> 1844738475200
	1844738475200 [label=AccumulateGrad]
	1844738475680 -> 1844738474624
	1845552227056 [label="stages.2.blocks.7.token_mixer.dwconv_h.bias
 (48)" fillcolor=lightblue]
	1845552227056 -> 1844738475680
	1844738475680 [label=AccumulateGrad]
	1844738474336 -> 1844738474192
	1845552227216 [label="stages.2.blocks.7.norm.weight
 (384)" fillcolor=lightblue]
	1845552227216 -> 1844738474336
	1844738474336 [label=AccumulateGrad]
	1844738474288 -> 1844738474192
	1845552227296 [label="stages.2.blocks.7.norm.bias
 (384)" fillcolor=lightblue]
	1845552227296 -> 1844738474288
	1844738474288 [label=AccumulateGrad]
	1844738474144 -> 1844708573136
	1845552227776 [label="stages.2.blocks.7.mlp.fc1.weight
 (1536, 384, 1, 1)" fillcolor=lightblue]
	1845552227776 -> 1844738474144
	1844738474144 [label=AccumulateGrad]
	1844738474048 -> 1844708573136
	1845552227856 [label="stages.2.blocks.7.mlp.fc1.bias
 (1536)" fillcolor=lightblue]
	1845552227856 -> 1844738474048
	1844738474048 [label=AccumulateGrad]
	1844708572992 -> 1844708572896
	1845552228016 [label="stages.2.blocks.7.mlp.fc2.weight
 (384, 1536, 1, 1)" fillcolor=lightblue]
	1845552228016 -> 1844708572992
	1844708572992 [label=AccumulateGrad]
	1844708572944 -> 1844708572896
	1845552228096 [label="stages.2.blocks.7.mlp.fc2.bias
 (384)" fillcolor=lightblue]
	1845552228096 -> 1844708572944
	1844708572944 [label=AccumulateGrad]
	1844708572848 -> 1844708572752
	1844708572848 [label=ReshapeAliasBackward0]
	1844708573088 -> 1844708572848
	1845552227936 [label="stages.2.blocks.7.gamma
 (384)" fillcolor=lightblue]
	1845552227936 -> 1844708573088
	1844708573088 [label=AccumulateGrad]
	1844708572608 -> 1844708571360
	1844708572416 -> 1844708572272
	1844708572416 [label=ConvolutionBackward0]
	1844708572464 -> 1844708572416
	1844708572800 -> 1844708572416
	1845552228336 [label="stages.2.blocks.8.token_mixer.dwconv_hw.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	1845552228336 -> 1844708572800
	1844708572800 [label=AccumulateGrad]
	1844708572656 -> 1844708572416
	1845552228416 [label="stages.2.blocks.8.token_mixer.dwconv_hw.bias
 (48)" fillcolor=lightblue]
	1845552228416 -> 1844708572656
	1844708572656 [label=AccumulateGrad]
	1844708572368 -> 1844708572272
	1844708572368 [label=ConvolutionBackward0]
	1844708572464 -> 1844708572368
	1844708572704 -> 1844708572368
	1845552228576 [label="stages.2.blocks.8.token_mixer.dwconv_w.weight
 (48, 1, 1, 11)" fillcolor=lightblue]
	1845552228576 -> 1844708572704
	1844708572704 [label=AccumulateGrad]
	1844738474672 -> 1844708572368
	1845552228656 [label="stages.2.blocks.8.token_mixer.dwconv_w.bias
 (48)" fillcolor=lightblue]
	1845552228656 -> 1844738474672
	1844738474672 [label=AccumulateGrad]
	1844708572512 -> 1844708572272
	1844708572512 [label=ConvolutionBackward0]
	1844708572464 -> 1844708572512
	1844738474096 -> 1844708572512
	1845552228816 [label="stages.2.blocks.8.token_mixer.dwconv_h.weight
 (48, 1, 11, 1)" fillcolor=lightblue]
	1845552228816 -> 1844738474096
	1844738474096 [label=AccumulateGrad]
	1844738474432 -> 1844708572512
	1845552228896 [label="stages.2.blocks.8.token_mixer.dwconv_h.bias
 (48)" fillcolor=lightblue]
	1845552228896 -> 1844738474432
	1844738474432 [label=AccumulateGrad]
	1844708572224 -> 1844708572080
	1845552229056 [label="stages.2.blocks.8.norm.weight
 (384)" fillcolor=lightblue]
	1845552229056 -> 1844708572224
	1844708572224 [label=AccumulateGrad]
	1844708572176 -> 1844708572080
	1845552229136 [label="stages.2.blocks.8.norm.bias
 (384)" fillcolor=lightblue]
	1845552229136 -> 1844708572176
	1844708572176 [label=AccumulateGrad]
	1844708572032 -> 1844708571984
	1845552229616 [label="stages.2.blocks.8.mlp.fc1.weight
 (1536, 384, 1, 1)" fillcolor=lightblue]
	1845552229616 -> 1844708572032
	1844708572032 [label=AccumulateGrad]
	1844708571888 -> 1844708571984
	1845552229696 [label="stages.2.blocks.8.mlp.fc1.bias
 (1536)" fillcolor=lightblue]
	1845552229696 -> 1844708571888
	1844708571888 [label=AccumulateGrad]
	1844708571744 -> 1844708571648
	1845552229856 [label="stages.2.blocks.8.mlp.fc2.weight
 (384, 1536, 1, 1)" fillcolor=lightblue]
	1845552229856 -> 1844708571744
	1844708571744 [label=AccumulateGrad]
	1844708571696 -> 1844708571648
	1845552229936 [label="stages.2.blocks.8.mlp.fc2.bias
 (384)" fillcolor=lightblue]
	1845552229936 -> 1844708571696
	1844708571696 [label=AccumulateGrad]
	1844708571600 -> 1844708571504
	1844708571600 [label=ReshapeAliasBackward0]
	1844708572128 -> 1844708571600
	1845552229776 [label="stages.2.blocks.8.gamma
 (384)" fillcolor=lightblue]
	1845552229776 -> 1844708572128
	1844708572128 [label=AccumulateGrad]
	1844708571360 -> 1844708570112
	1844708571168 -> 1844708571024
	1844708571168 [label=ConvolutionBackward0]
	1844708571216 -> 1844708571168
	1844708571552 -> 1844708571168
	1845552230176 [label="stages.2.blocks.9.token_mixer.dwconv_hw.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	1845552230176 -> 1844708571552
	1844708571552 [label=AccumulateGrad]
	1844708571408 -> 1844708571168
	1845552230256 [label="stages.2.blocks.9.token_mixer.dwconv_hw.bias
 (48)" fillcolor=lightblue]
	1845552230256 -> 1844708571408
	1844708571408 [label=AccumulateGrad]
	1844708571120 -> 1844708571024
	1844708571120 [label=ConvolutionBackward0]
	1844708571216 -> 1844708571120
	1844708572560 -> 1844708571120
	1845552230096 [label="stages.2.blocks.9.token_mixer.dwconv_w.weight
 (48, 1, 1, 11)" fillcolor=lightblue]
	1845552230096 -> 1844708572560
	1844708572560 [label=AccumulateGrad]
	1844708571936 -> 1844708571120
	1845552230416 [label="stages.2.blocks.9.token_mixer.dwconv_w.bias
 (48)" fillcolor=lightblue]
	1845552230416 -> 1844708571936
	1844708571936 [label=AccumulateGrad]
	1844708571264 -> 1844708571024
	1844708571264 [label=ConvolutionBackward0]
	1844708571216 -> 1844708571264
	1844708571840 -> 1844708571264
	1845552230496 [label="stages.2.blocks.9.token_mixer.dwconv_h.weight
 (48, 1, 11, 1)" fillcolor=lightblue]
	1845552230496 -> 1844708571840
	1844708571840 [label=AccumulateGrad]
	1844708572320 -> 1844708571264
	1845552230576 [label="stages.2.blocks.9.token_mixer.dwconv_h.bias
 (48)" fillcolor=lightblue]
	1845552230576 -> 1844708572320
	1844708572320 [label=AccumulateGrad]
	1844708570976 -> 1844708570832
	1845552230736 [label="stages.2.blocks.9.norm.weight
 (384)" fillcolor=lightblue]
	1845552230736 -> 1844708570976
	1844708570976 [label=AccumulateGrad]
	1844708570928 -> 1844708570832
	1845552230816 [label="stages.2.blocks.9.norm.bias
 (384)" fillcolor=lightblue]
	1845552230816 -> 1844708570928
	1844708570928 [label=AccumulateGrad]
	1844708570784 -> 1844708570736
	1845552231296 [label="stages.2.blocks.9.mlp.fc1.weight
 (1536, 384, 1, 1)" fillcolor=lightblue]
	1845552231296 -> 1844708570784
	1844708570784 [label=AccumulateGrad]
	1844708570640 -> 1844708570736
	1845552231376 [label="stages.2.blocks.9.mlp.fc1.bias
 (1536)" fillcolor=lightblue]
	1845552231376 -> 1844708570640
	1844708570640 [label=AccumulateGrad]
	1844708570496 -> 1844708570400
	1845552231536 [label="stages.2.blocks.9.mlp.fc2.weight
 (384, 1536, 1, 1)" fillcolor=lightblue]
	1845552231536 -> 1844708570496
	1844708570496 [label=AccumulateGrad]
	1844708570448 -> 1844708570400
	1845552231616 [label="stages.2.blocks.9.mlp.fc2.bias
 (384)" fillcolor=lightblue]
	1845552231616 -> 1844708570448
	1844708570448 [label=AccumulateGrad]
	1844708570352 -> 1844708570256
	1844708570352 [label=ReshapeAliasBackward0]
	1844708570880 -> 1844708570352
	1845552231456 [label="stages.2.blocks.9.gamma
 (384)" fillcolor=lightblue]
	1845552231456 -> 1844708570880
	1844708570880 [label=AccumulateGrad]
	1844708570112 -> 1844708568864
	1844708569920 -> 1844708569776
	1844708569920 [label=ConvolutionBackward0]
	1844708569968 -> 1844708569920
	1844708570304 -> 1844708569920
	1845552231856 [label="stages.2.blocks.10.token_mixer.dwconv_hw.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	1845552231856 -> 1844708570304
	1844708570304 [label=AccumulateGrad]
	1844708570160 -> 1844708569920
	1845552231936 [label="stages.2.blocks.10.token_mixer.dwconv_hw.bias
 (48)" fillcolor=lightblue]
	1845552231936 -> 1844708570160
	1844708570160 [label=AccumulateGrad]
	1844708569872 -> 1844708569776
	1844708569872 [label=ConvolutionBackward0]
	1844708569968 -> 1844708569872
	1844708571312 -> 1844708569872
	1845552232096 [label="stages.2.blocks.10.token_mixer.dwconv_w.weight
 (48, 1, 1, 11)" fillcolor=lightblue]
	1845552232096 -> 1844708571312
	1844708571312 [label=AccumulateGrad]
	1844708570688 -> 1844708569872
	1845552232176 [label="stages.2.blocks.10.token_mixer.dwconv_w.bias
 (48)" fillcolor=lightblue]
	1845552232176 -> 1844708570688
	1844708570688 [label=AccumulateGrad]
	1844708570016 -> 1844708569776
	1844708570016 [label=ConvolutionBackward0]
	1844708569968 -> 1844708570016
	1844708570592 -> 1844708570016
	1845552232336 [label="stages.2.blocks.10.token_mixer.dwconv_h.weight
 (48, 1, 11, 1)" fillcolor=lightblue]
	1845552232336 -> 1844708570592
	1844708570592 [label=AccumulateGrad]
	1844708571072 -> 1844708570016
	1845552232416 [label="stages.2.blocks.10.token_mixer.dwconv_h.bias
 (48)" fillcolor=lightblue]
	1845552232416 -> 1844708571072
	1844708571072 [label=AccumulateGrad]
	1844708569728 -> 1844708569584
	1845552232576 [label="stages.2.blocks.10.norm.weight
 (384)" fillcolor=lightblue]
	1845552232576 -> 1844708569728
	1844708569728 [label=AccumulateGrad]
	1844708569680 -> 1844708569584
	1845552232656 [label="stages.2.blocks.10.norm.bias
 (384)" fillcolor=lightblue]
	1845552232656 -> 1844708569680
	1844708569680 [label=AccumulateGrad]
	1844708569536 -> 1844708569488
	1845552233136 [label="stages.2.blocks.10.mlp.fc1.weight
 (1536, 384, 1, 1)" fillcolor=lightblue]
	1845552233136 -> 1844708569536
	1844708569536 [label=AccumulateGrad]
	1844708569392 -> 1844708569488
	1845552233216 [label="stages.2.blocks.10.mlp.fc1.bias
 (1536)" fillcolor=lightblue]
	1845552233216 -> 1844708569392
	1844708569392 [label=AccumulateGrad]
	1844708569248 -> 1844708569152
	1845552233376 [label="stages.2.blocks.10.mlp.fc2.weight
 (384, 1536, 1, 1)" fillcolor=lightblue]
	1845552233376 -> 1844708569248
	1844708569248 [label=AccumulateGrad]
	1844708569200 -> 1844708569152
	1845552233456 [label="stages.2.blocks.10.mlp.fc2.bias
 (384)" fillcolor=lightblue]
	1845552233456 -> 1844708569200
	1844708569200 [label=AccumulateGrad]
	1844708569104 -> 1844708569008
	1844708569104 [label=ReshapeAliasBackward0]
	1844708569632 -> 1844708569104
	1845552233296 [label="stages.2.blocks.10.gamma
 (384)" fillcolor=lightblue]
	1845552233296 -> 1844708569632
	1844708569632 [label=AccumulateGrad]
	1844708568864 -> 1844708567616
	1844708568672 -> 1844708568528
	1844708568672 [label=ConvolutionBackward0]
	1844708568720 -> 1844708568672
	1844708569056 -> 1844708568672
	1845552233696 [label="stages.2.blocks.11.token_mixer.dwconv_hw.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	1845552233696 -> 1844708569056
	1844708569056 [label=AccumulateGrad]
	1844708568912 -> 1844708568672
	1845552233776 [label="stages.2.blocks.11.token_mixer.dwconv_hw.bias
 (48)" fillcolor=lightblue]
	1845552233776 -> 1844708568912
	1844708568912 [label=AccumulateGrad]
	1844708568624 -> 1844708568528
	1844708568624 [label=ConvolutionBackward0]
	1844708568720 -> 1844708568624
	1844708570064 -> 1844708568624
	1845552233936 [label="stages.2.blocks.11.token_mixer.dwconv_w.weight
 (48, 1, 1, 11)" fillcolor=lightblue]
	1845552233936 -> 1844708570064
	1844708570064 [label=AccumulateGrad]
	1844708569440 -> 1844708568624
	1845552234016 [label="stages.2.blocks.11.token_mixer.dwconv_w.bias
 (48)" fillcolor=lightblue]
	1845552234016 -> 1844708569440
	1844708569440 [label=AccumulateGrad]
	1844708568768 -> 1844708568528
	1844708568768 [label=ConvolutionBackward0]
	1844708568720 -> 1844708568768
	1844708569344 -> 1844708568768
	1845552234176 [label="stages.2.blocks.11.token_mixer.dwconv_h.weight
 (48, 1, 11, 1)" fillcolor=lightblue]
	1845552234176 -> 1844708569344
	1844708569344 [label=AccumulateGrad]
	1844708569824 -> 1844708568768
	1845552234256 [label="stages.2.blocks.11.token_mixer.dwconv_h.bias
 (48)" fillcolor=lightblue]
	1845552234256 -> 1844708569824
	1844708569824 [label=AccumulateGrad]
	1844708568480 -> 1844708568336
	1845552234416 [label="stages.2.blocks.11.norm.weight
 (384)" fillcolor=lightblue]
	1845552234416 -> 1844708568480
	1844708568480 [label=AccumulateGrad]
	1844708568432 -> 1844708568336
	1846370762816 [label="stages.2.blocks.11.norm.bias
 (384)" fillcolor=lightblue]
	1846370762816 -> 1844708568432
	1844708568432 [label=AccumulateGrad]
	1844708568288 -> 1844708568240
	1846370763296 [label="stages.2.blocks.11.mlp.fc1.weight
 (1536, 384, 1, 1)" fillcolor=lightblue]
	1846370763296 -> 1844708568288
	1844708568288 [label=AccumulateGrad]
	1844708568144 -> 1844708568240
	1846370763376 [label="stages.2.blocks.11.mlp.fc1.bias
 (1536)" fillcolor=lightblue]
	1846370763376 -> 1844708568144
	1844708568144 [label=AccumulateGrad]
	1844708568000 -> 1844708567904
	1846370763536 [label="stages.2.blocks.11.mlp.fc2.weight
 (384, 1536, 1, 1)" fillcolor=lightblue]
	1846370763536 -> 1844708568000
	1844708568000 [label=AccumulateGrad]
	1844708567952 -> 1844708567904
	1846370763616 [label="stages.2.blocks.11.mlp.fc2.bias
 (384)" fillcolor=lightblue]
	1846370763616 -> 1844708567952
	1844708567952 [label=AccumulateGrad]
	1844708567856 -> 1844708567760
	1844708567856 [label=ReshapeAliasBackward0]
	1844708568384 -> 1844708567856
	1846370763456 [label="stages.2.blocks.11.gamma
 (384)" fillcolor=lightblue]
	1846370763456 -> 1844708568384
	1844708568384 [label=AccumulateGrad]
	1844708567616 -> 1844708566368
	1844708567424 -> 1844708567280
	1844708567424 [label=ConvolutionBackward0]
	1844708567472 -> 1844708567424
	1844708567808 -> 1844708567424
	1846370763856 [label="stages.2.blocks.12.token_mixer.dwconv_hw.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	1846370763856 -> 1844708567808
	1844708567808 [label=AccumulateGrad]
	1844708567664 -> 1844708567424
	1846370763936 [label="stages.2.blocks.12.token_mixer.dwconv_hw.bias
 (48)" fillcolor=lightblue]
	1846370763936 -> 1844708567664
	1844708567664 [label=AccumulateGrad]
	1844708567376 -> 1844708567280
	1844708567376 [label=ConvolutionBackward0]
	1844708567472 -> 1844708567376
	1844708568816 -> 1844708567376
	1846370764096 [label="stages.2.blocks.12.token_mixer.dwconv_w.weight
 (48, 1, 1, 11)" fillcolor=lightblue]
	1846370764096 -> 1844708568816
	1844708568816 [label=AccumulateGrad]
	1844708568192 -> 1844708567376
	1846370764176 [label="stages.2.blocks.12.token_mixer.dwconv_w.bias
 (48)" fillcolor=lightblue]
	1846370764176 -> 1844708568192
	1844708568192 [label=AccumulateGrad]
	1844708567520 -> 1844708567280
	1844708567520 [label=ConvolutionBackward0]
	1844708567472 -> 1844708567520
	1844708568096 -> 1844708567520
	1846370764336 [label="stages.2.blocks.12.token_mixer.dwconv_h.weight
 (48, 1, 11, 1)" fillcolor=lightblue]
	1846370764336 -> 1844708568096
	1844708568096 [label=AccumulateGrad]
	1844708568576 -> 1844708567520
	1846370764416 [label="stages.2.blocks.12.token_mixer.dwconv_h.bias
 (48)" fillcolor=lightblue]
	1846370764416 -> 1844708568576
	1844708568576 [label=AccumulateGrad]
	1844708567232 -> 1844708567088
	1846370764576 [label="stages.2.blocks.12.norm.weight
 (384)" fillcolor=lightblue]
	1846370764576 -> 1844708567232
	1844708567232 [label=AccumulateGrad]
	1844708567184 -> 1844708567088
	1846370764656 [label="stages.2.blocks.12.norm.bias
 (384)" fillcolor=lightblue]
	1846370764656 -> 1844708567184
	1844708567184 [label=AccumulateGrad]
	1844708567040 -> 1844708566992
	1846370765136 [label="stages.2.blocks.12.mlp.fc1.weight
 (1536, 384, 1, 1)" fillcolor=lightblue]
	1846370765136 -> 1844708567040
	1844708567040 [label=AccumulateGrad]
	1844708566896 -> 1844708566992
	1846370765216 [label="stages.2.blocks.12.mlp.fc1.bias
 (1536)" fillcolor=lightblue]
	1846370765216 -> 1844708566896
	1844708566896 [label=AccumulateGrad]
	1844708566752 -> 1844708566656
	1846370765376 [label="stages.2.blocks.12.mlp.fc2.weight
 (384, 1536, 1, 1)" fillcolor=lightblue]
	1846370765376 -> 1844708566752
	1844708566752 [label=AccumulateGrad]
	1844708566704 -> 1844708566656
	1846370765456 [label="stages.2.blocks.12.mlp.fc2.bias
 (384)" fillcolor=lightblue]
	1846370765456 -> 1844708566704
	1844708566704 [label=AccumulateGrad]
	1844708566608 -> 1844708566512
	1844708566608 [label=ReshapeAliasBackward0]
	1844708567136 -> 1844708566608
	1846370765296 [label="stages.2.blocks.12.gamma
 (384)" fillcolor=lightblue]
	1846370765296 -> 1844708567136
	1844708567136 [label=AccumulateGrad]
	1844708566368 -> 1844708565120
	1844708566176 -> 1844708566032
	1844708566176 [label=ConvolutionBackward0]
	1844708566224 -> 1844708566176
	1844708566560 -> 1844708566176
	1846370765696 [label="stages.2.blocks.13.token_mixer.dwconv_hw.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	1846370765696 -> 1844708566560
	1844708566560 [label=AccumulateGrad]
	1844708566416 -> 1844708566176
	1846370765776 [label="stages.2.blocks.13.token_mixer.dwconv_hw.bias
 (48)" fillcolor=lightblue]
	1846370765776 -> 1844708566416
	1844708566416 [label=AccumulateGrad]
	1844708566128 -> 1844708566032
	1844708566128 [label=ConvolutionBackward0]
	1844708566224 -> 1844708566128
	1844708567568 -> 1844708566128
	1846370765936 [label="stages.2.blocks.13.token_mixer.dwconv_w.weight
 (48, 1, 1, 11)" fillcolor=lightblue]
	1846370765936 -> 1844708567568
	1844708567568 [label=AccumulateGrad]
	1844708566944 -> 1844708566128
	1846370766016 [label="stages.2.blocks.13.token_mixer.dwconv_w.bias
 (48)" fillcolor=lightblue]
	1846370766016 -> 1844708566944
	1844708566944 [label=AccumulateGrad]
	1844708566272 -> 1844708566032
	1844708566272 [label=ConvolutionBackward0]
	1844708566224 -> 1844708566272
	1844708566848 -> 1844708566272
	1846370766176 [label="stages.2.blocks.13.token_mixer.dwconv_h.weight
 (48, 1, 11, 1)" fillcolor=lightblue]
	1846370766176 -> 1844708566848
	1844708566848 [label=AccumulateGrad]
	1844708567328 -> 1844708566272
	1846370766256 [label="stages.2.blocks.13.token_mixer.dwconv_h.bias
 (48)" fillcolor=lightblue]
	1846370766256 -> 1844708567328
	1844708567328 [label=AccumulateGrad]
	1844708565984 -> 1844708565840
	1846370766416 [label="stages.2.blocks.13.norm.weight
 (384)" fillcolor=lightblue]
	1846370766416 -> 1844708565984
	1844708565984 [label=AccumulateGrad]
	1844708565936 -> 1844708565840
	1846370766496 [label="stages.2.blocks.13.norm.bias
 (384)" fillcolor=lightblue]
	1846370766496 -> 1844708565936
	1844708565936 [label=AccumulateGrad]
	1844708565792 -> 1844708565744
	1846370766896 [label="stages.2.blocks.13.mlp.fc1.weight
 (1536, 384, 1, 1)" fillcolor=lightblue]
	1846370766896 -> 1844708565792
	1844708565792 [label=AccumulateGrad]
	1844708565648 -> 1844708565744
	1846370766976 [label="stages.2.blocks.13.mlp.fc1.bias
 (1536)" fillcolor=lightblue]
	1846370766976 -> 1844708565648
	1844708565648 [label=AccumulateGrad]
	1844708565504 -> 1844708565408
	1846370767136 [label="stages.2.blocks.13.mlp.fc2.weight
 (384, 1536, 1, 1)" fillcolor=lightblue]
	1846370767136 -> 1844708565504
	1844708565504 [label=AccumulateGrad]
	1844708565456 -> 1844708565408
	1846370767216 [label="stages.2.blocks.13.mlp.fc2.bias
 (384)" fillcolor=lightblue]
	1846370767216 -> 1844708565456
	1844708565456 [label=AccumulateGrad]
	1844708565360 -> 1844708565264
	1844708565360 [label=ReshapeAliasBackward0]
	1844708565888 -> 1844708565360
	1846370767056 [label="stages.2.blocks.13.gamma
 (384)" fillcolor=lightblue]
	1846370767056 -> 1844708565888
	1844708565888 [label=AccumulateGrad]
	1844708565120 -> 1844708563872
	1844708564928 -> 1844708564784
	1844708564928 [label=ConvolutionBackward0]
	1844708564976 -> 1844708564928
	1844708565312 -> 1844708564928
	1846370767456 [label="stages.2.blocks.14.token_mixer.dwconv_hw.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	1846370767456 -> 1844708565312
	1844708565312 [label=AccumulateGrad]
	1844708565168 -> 1844708564928
	1846370767536 [label="stages.2.blocks.14.token_mixer.dwconv_hw.bias
 (48)" fillcolor=lightblue]
	1846370767536 -> 1844708565168
	1844708565168 [label=AccumulateGrad]
	1844708564880 -> 1844708564784
	1844708564880 [label=ConvolutionBackward0]
	1844708564976 -> 1844708564880
	1844708566320 -> 1844708564880
	1846370767696 [label="stages.2.blocks.14.token_mixer.dwconv_w.weight
 (48, 1, 1, 11)" fillcolor=lightblue]
	1846370767696 -> 1844708566320
	1844708566320 [label=AccumulateGrad]
	1844708565696 -> 1844708564880
	1846370767776 [label="stages.2.blocks.14.token_mixer.dwconv_w.bias
 (48)" fillcolor=lightblue]
	1846370767776 -> 1844708565696
	1844708565696 [label=AccumulateGrad]
	1844708565024 -> 1844708564784
	1844708565024 [label=ConvolutionBackward0]
	1844708564976 -> 1844708565024
	1844708565600 -> 1844708565024
	1846370767936 [label="stages.2.blocks.14.token_mixer.dwconv_h.weight
 (48, 1, 11, 1)" fillcolor=lightblue]
	1846370767936 -> 1844708565600
	1844708565600 [label=AccumulateGrad]
	1844708566080 -> 1844708565024
	1846370768016 [label="stages.2.blocks.14.token_mixer.dwconv_h.bias
 (48)" fillcolor=lightblue]
	1846370768016 -> 1844708566080
	1844708566080 [label=AccumulateGrad]
	1844708564736 -> 1844708564592
	1846370768176 [label="stages.2.blocks.14.norm.weight
 (384)" fillcolor=lightblue]
	1846370768176 -> 1844708564736
	1844708564736 [label=AccumulateGrad]
	1844708564688 -> 1844708564592
	1846370768256 [label="stages.2.blocks.14.norm.bias
 (384)" fillcolor=lightblue]
	1846370768256 -> 1844708564688
	1844708564688 [label=AccumulateGrad]
	1844708564544 -> 1844708564496
	1846370768736 [label="stages.2.blocks.14.mlp.fc1.weight
 (1536, 384, 1, 1)" fillcolor=lightblue]
	1846370768736 -> 1844708564544
	1844708564544 [label=AccumulateGrad]
	1844708564400 -> 1844708564496
	1846370768816 [label="stages.2.blocks.14.mlp.fc1.bias
 (1536)" fillcolor=lightblue]
	1846370768816 -> 1844708564400
	1844708564400 [label=AccumulateGrad]
	1844708564256 -> 1844708564160
	1846370768976 [label="stages.2.blocks.14.mlp.fc2.weight
 (384, 1536, 1, 1)" fillcolor=lightblue]
	1846370768976 -> 1844708564256
	1844708564256 [label=AccumulateGrad]
	1844708564208 -> 1844708564160
	1846370769056 [label="stages.2.blocks.14.mlp.fc2.bias
 (384)" fillcolor=lightblue]
	1846370769056 -> 1844708564208
	1844708564208 [label=AccumulateGrad]
	1844708564112 -> 1844708564016
	1844708564112 [label=ReshapeAliasBackward0]
	1844708564640 -> 1844708564112
	1846370768896 [label="stages.2.blocks.14.gamma
 (384)" fillcolor=lightblue]
	1846370768896 -> 1844708564640
	1844708564640 [label=AccumulateGrad]
	1844708563872 -> 1844708562624
	1844708563680 -> 1844708563536
	1844708563680 [label=ConvolutionBackward0]
	1844708563728 -> 1844708563680
	1844708564064 -> 1844708563680
	1846370769296 [label="stages.2.blocks.15.token_mixer.dwconv_hw.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	1846370769296 -> 1844708564064
	1844708564064 [label=AccumulateGrad]
	1844708563920 -> 1844708563680
	1846370769376 [label="stages.2.blocks.15.token_mixer.dwconv_hw.bias
 (48)" fillcolor=lightblue]
	1846370769376 -> 1844708563920
	1844708563920 [label=AccumulateGrad]
	1844708563632 -> 1844708563536
	1844708563632 [label=ConvolutionBackward0]
	1844708563728 -> 1844708563632
	1844708565072 -> 1844708563632
	1846370769536 [label="stages.2.blocks.15.token_mixer.dwconv_w.weight
 (48, 1, 1, 11)" fillcolor=lightblue]
	1846370769536 -> 1844708565072
	1844708565072 [label=AccumulateGrad]
	1844708564448 -> 1844708563632
	1846370769616 [label="stages.2.blocks.15.token_mixer.dwconv_w.bias
 (48)" fillcolor=lightblue]
	1846370769616 -> 1844708564448
	1844708564448 [label=AccumulateGrad]
	1844708563776 -> 1844708563536
	1844708563776 [label=ConvolutionBackward0]
	1844708563728 -> 1844708563776
	1844708564352 -> 1844708563776
	1846370769776 [label="stages.2.blocks.15.token_mixer.dwconv_h.weight
 (48, 1, 11, 1)" fillcolor=lightblue]
	1846370769776 -> 1844708564352
	1844708564352 [label=AccumulateGrad]
	1844708564832 -> 1844708563776
	1846370769856 [label="stages.2.blocks.15.token_mixer.dwconv_h.bias
 (48)" fillcolor=lightblue]
	1846370769856 -> 1844708564832
	1844708564832 [label=AccumulateGrad]
	1844708563488 -> 1844708563344
	1846370770016 [label="stages.2.blocks.15.norm.weight
 (384)" fillcolor=lightblue]
	1846370770016 -> 1844708563488
	1844708563488 [label=AccumulateGrad]
	1844708563440 -> 1844708563344
	1846370770096 [label="stages.2.blocks.15.norm.bias
 (384)" fillcolor=lightblue]
	1846370770096 -> 1844708563440
	1844708563440 [label=AccumulateGrad]
	1844708563296 -> 1844708563248
	1846370770496 [label="stages.2.blocks.15.mlp.fc1.weight
 (1536, 384, 1, 1)" fillcolor=lightblue]
	1846370770496 -> 1844708563296
	1844708563296 [label=AccumulateGrad]
	1844708563152 -> 1844708563248
	1846370770576 [label="stages.2.blocks.15.mlp.fc1.bias
 (1536)" fillcolor=lightblue]
	1846370770576 -> 1844708563152
	1844708563152 [label=AccumulateGrad]
	1844708563008 -> 1844708562912
	1846370770736 [label="stages.2.blocks.15.mlp.fc2.weight
 (384, 1536, 1, 1)" fillcolor=lightblue]
	1846370770736 -> 1844708563008
	1844708563008 [label=AccumulateGrad]
	1844708562960 -> 1844708562912
	1846370770816 [label="stages.2.blocks.15.mlp.fc2.bias
 (384)" fillcolor=lightblue]
	1846370770816 -> 1844708562960
	1844708562960 [label=AccumulateGrad]
	1844708562864 -> 1844708562768
	1844708562864 [label=ReshapeAliasBackward0]
	1844708563392 -> 1844708562864
	1846370770656 [label="stages.2.blocks.15.gamma
 (384)" fillcolor=lightblue]
	1846370770656 -> 1844708563392
	1844708563392 [label=AccumulateGrad]
	1844708562624 -> 1844708561376
	1844708562432 -> 1844708562288
	1844708562432 [label=ConvolutionBackward0]
	1844708562480 -> 1844708562432
	1844708562816 -> 1844708562432
	1846370771056 [label="stages.2.blocks.16.token_mixer.dwconv_hw.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	1846370771056 -> 1844708562816
	1844708562816 [label=AccumulateGrad]
	1844708562672 -> 1844708562432
	1846370771136 [label="stages.2.blocks.16.token_mixer.dwconv_hw.bias
 (48)" fillcolor=lightblue]
	1846370771136 -> 1844708562672
	1844708562672 [label=AccumulateGrad]
	1844708562384 -> 1844708562288
	1844708562384 [label=ConvolutionBackward0]
	1844708562480 -> 1844708562384
	1844708563824 -> 1844708562384
	1846370771296 [label="stages.2.blocks.16.token_mixer.dwconv_w.weight
 (48, 1, 1, 11)" fillcolor=lightblue]
	1846370771296 -> 1844708563824
	1844708563824 [label=AccumulateGrad]
	1844708563200 -> 1844708562384
	1846370771376 [label="stages.2.blocks.16.token_mixer.dwconv_w.bias
 (48)" fillcolor=lightblue]
	1846370771376 -> 1844708563200
	1844708563200 [label=AccumulateGrad]
	1844708562528 -> 1844708562288
	1844708562528 [label=ConvolutionBackward0]
	1844708562480 -> 1844708562528
	1844708563104 -> 1844708562528
	1846370771536 [label="stages.2.blocks.16.token_mixer.dwconv_h.weight
 (48, 1, 11, 1)" fillcolor=lightblue]
	1846370771536 -> 1844708563104
	1844708563104 [label=AccumulateGrad]
	1844708563584 -> 1844708562528
	1846370771616 [label="stages.2.blocks.16.token_mixer.dwconv_h.bias
 (48)" fillcolor=lightblue]
	1846370771616 -> 1844708563584
	1844708563584 [label=AccumulateGrad]
	1844708562240 -> 1844708562096
	1846370771776 [label="stages.2.blocks.16.norm.weight
 (384)" fillcolor=lightblue]
	1846370771776 -> 1844708562240
	1844708562240 [label=AccumulateGrad]
	1844708562192 -> 1844708562096
	1846370771856 [label="stages.2.blocks.16.norm.bias
 (384)" fillcolor=lightblue]
	1846370771856 -> 1844708562192
	1844708562192 [label=AccumulateGrad]
	1844708562048 -> 1844708562000
	1846370772336 [label="stages.2.blocks.16.mlp.fc1.weight
 (1536, 384, 1, 1)" fillcolor=lightblue]
	1846370772336 -> 1844708562048
	1844708562048 [label=AccumulateGrad]
	1844708561904 -> 1844708562000
	1846370772416 [label="stages.2.blocks.16.mlp.fc1.bias
 (1536)" fillcolor=lightblue]
	1846370772416 -> 1844708561904
	1844708561904 [label=AccumulateGrad]
	1844708561760 -> 1844708561664
	1846370772576 [label="stages.2.blocks.16.mlp.fc2.weight
 (384, 1536, 1, 1)" fillcolor=lightblue]
	1846370772576 -> 1844708561760
	1844708561760 [label=AccumulateGrad]
	1844708561712 -> 1844708561664
	1846370772656 [label="stages.2.blocks.16.mlp.fc2.bias
 (384)" fillcolor=lightblue]
	1846370772656 -> 1844708561712
	1844708561712 [label=AccumulateGrad]
	1844708561616 -> 1844708561520
	1844708561616 [label=ReshapeAliasBackward0]
	1844708562144 -> 1844708561616
	1846370772496 [label="stages.2.blocks.16.gamma
 (384)" fillcolor=lightblue]
	1846370772496 -> 1844708562144
	1844708562144 [label=AccumulateGrad]
	1844708561376 -> 1844708560128
	1844708561184 -> 1844708561040
	1844708561184 [label=ConvolutionBackward0]
	1844708561232 -> 1844708561184
	1844708561568 -> 1844708561184
	1846370772896 [label="stages.2.blocks.17.token_mixer.dwconv_hw.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	1846370772896 -> 1844708561568
	1844708561568 [label=AccumulateGrad]
	1844708561424 -> 1844708561184
	1846370772976 [label="stages.2.blocks.17.token_mixer.dwconv_hw.bias
 (48)" fillcolor=lightblue]
	1846370772976 -> 1844708561424
	1844708561424 [label=AccumulateGrad]
	1844708561136 -> 1844708561040
	1844708561136 [label=ConvolutionBackward0]
	1844708561232 -> 1844708561136
	1844708562576 -> 1844708561136
	1846370773136 [label="stages.2.blocks.17.token_mixer.dwconv_w.weight
 (48, 1, 1, 11)" fillcolor=lightblue]
	1846370773136 -> 1844708562576
	1844708562576 [label=AccumulateGrad]
	1844708561952 -> 1844708561136
	1846370773216 [label="stages.2.blocks.17.token_mixer.dwconv_w.bias
 (48)" fillcolor=lightblue]
	1846370773216 -> 1844708561952
	1844708561952 [label=AccumulateGrad]
	1844708561280 -> 1844708561040
	1844708561280 [label=ConvolutionBackward0]
	1844708561232 -> 1844708561280
	1844708561856 -> 1844708561280
	1846370773376 [label="stages.2.blocks.17.token_mixer.dwconv_h.weight
 (48, 1, 11, 1)" fillcolor=lightblue]
	1846370773376 -> 1844708561856
	1844708561856 [label=AccumulateGrad]
	1844708562336 -> 1844708561280
	1846370773456 [label="stages.2.blocks.17.token_mixer.dwconv_h.bias
 (48)" fillcolor=lightblue]
	1846370773456 -> 1844708562336
	1844708562336 [label=AccumulateGrad]
	1844708560992 -> 1844708560848
	1846370773616 [label="stages.2.blocks.17.norm.weight
 (384)" fillcolor=lightblue]
	1846370773616 -> 1844708560992
	1844708560992 [label=AccumulateGrad]
	1844708560944 -> 1844708560848
	1846370773696 [label="stages.2.blocks.17.norm.bias
 (384)" fillcolor=lightblue]
	1846370773696 -> 1844708560944
	1844708560944 [label=AccumulateGrad]
	1844708560800 -> 1844708560752
	1846370774176 [label="stages.2.blocks.17.mlp.fc1.weight
 (1536, 384, 1, 1)" fillcolor=lightblue]
	1846370774176 -> 1844708560800
	1844708560800 [label=AccumulateGrad]
	1844708560656 -> 1844708560752
	1846370774256 [label="stages.2.blocks.17.mlp.fc1.bias
 (1536)" fillcolor=lightblue]
	1846370774256 -> 1844708560656
	1844708560656 [label=AccumulateGrad]
	1844708560512 -> 1844708560416
	1846370774416 [label="stages.2.blocks.17.mlp.fc2.weight
 (384, 1536, 1, 1)" fillcolor=lightblue]
	1846370774416 -> 1844708560512
	1844708560512 [label=AccumulateGrad]
	1844708560464 -> 1844708560416
	1846370774496 [label="stages.2.blocks.17.mlp.fc2.bias
 (384)" fillcolor=lightblue]
	1846370774496 -> 1844708560464
	1844708560464 [label=AccumulateGrad]
	1844708560368 -> 1844708560272
	1844708560368 [label=ReshapeAliasBackward0]
	1844708560896 -> 1844708560368
	1846370774336 [label="stages.2.blocks.17.gamma
 (384)" fillcolor=lightblue]
	1846370774336 -> 1844708560896
	1844708560896 [label=AccumulateGrad]
	1844708560128 -> 1844708558880
	1844708559936 -> 1844708559792
	1844708559936 [label=ConvolutionBackward0]
	1844708559984 -> 1844708559936
	1844708560320 -> 1844708559936
	1846370774736 [label="stages.2.blocks.18.token_mixer.dwconv_hw.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	1846370774736 -> 1844708560320
	1844708560320 [label=AccumulateGrad]
	1844708560176 -> 1844708559936
	1846370774816 [label="stages.2.blocks.18.token_mixer.dwconv_hw.bias
 (48)" fillcolor=lightblue]
	1846370774816 -> 1844708560176
	1844708560176 [label=AccumulateGrad]
	1844708559888 -> 1844708559792
	1844708559888 [label=ConvolutionBackward0]
	1844708559984 -> 1844708559888
	1844708561328 -> 1844708559888
	1846370774976 [label="stages.2.blocks.18.token_mixer.dwconv_w.weight
 (48, 1, 1, 11)" fillcolor=lightblue]
	1846370774976 -> 1844708561328
	1844708561328 [label=AccumulateGrad]
	1844708560704 -> 1844708559888
	1846370775056 [label="stages.2.blocks.18.token_mixer.dwconv_w.bias
 (48)" fillcolor=lightblue]
	1846370775056 -> 1844708560704
	1844708560704 [label=AccumulateGrad]
	1844708560032 -> 1844708559792
	1844708560032 [label=ConvolutionBackward0]
	1844708559984 -> 1844708560032
	1844708560608 -> 1844708560032
	1846370775216 [label="stages.2.blocks.18.token_mixer.dwconv_h.weight
 (48, 1, 11, 1)" fillcolor=lightblue]
	1846370775216 -> 1844708560608
	1844708560608 [label=AccumulateGrad]
	1844708561088 -> 1844708560032
	1846370775296 [label="stages.2.blocks.18.token_mixer.dwconv_h.bias
 (48)" fillcolor=lightblue]
	1846370775296 -> 1844708561088
	1844708561088 [label=AccumulateGrad]
	1844708559744 -> 1844708559600
	1846370775456 [label="stages.2.blocks.18.norm.weight
 (384)" fillcolor=lightblue]
	1846370775456 -> 1844708559744
	1844708559744 [label=AccumulateGrad]
	1844708559696 -> 1844708559600
	1846370775536 [label="stages.2.blocks.18.norm.bias
 (384)" fillcolor=lightblue]
	1846370775536 -> 1844708559696
	1844708559696 [label=AccumulateGrad]
	1844708559552 -> 1844708559504
	1846370776016 [label="stages.2.blocks.18.mlp.fc1.weight
 (1536, 384, 1, 1)" fillcolor=lightblue]
	1846370776016 -> 1844708559552
	1844708559552 [label=AccumulateGrad]
	1844708559408 -> 1844708559504
	1846370776096 [label="stages.2.blocks.18.mlp.fc1.bias
 (1536)" fillcolor=lightblue]
	1846370776096 -> 1844708559408
	1844708559408 [label=AccumulateGrad]
	1844708559264 -> 1844708559168
	1846370776256 [label="stages.2.blocks.18.mlp.fc2.weight
 (384, 1536, 1, 1)" fillcolor=lightblue]
	1846370776256 -> 1844708559264
	1844708559264 [label=AccumulateGrad]
	1844708559216 -> 1844708559168
	1846370776336 [label="stages.2.blocks.18.mlp.fc2.bias
 (384)" fillcolor=lightblue]
	1846370776336 -> 1844708559216
	1844708559216 [label=AccumulateGrad]
	1844708559120 -> 1844708559024
	1844708559120 [label=ReshapeAliasBackward0]
	1844708559648 -> 1844708559120
	1846370776176 [label="stages.2.blocks.18.gamma
 (384)" fillcolor=lightblue]
	1846370776176 -> 1844708559648
	1844708559648 [label=AccumulateGrad]
	1844708558880 -> 1844708557632
	1844708558688 -> 1844708558544
	1844708558688 [label=ConvolutionBackward0]
	1844708558736 -> 1844708558688
	1844708559072 -> 1844708558688
	1846370776576 [label="stages.2.blocks.19.token_mixer.dwconv_hw.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	1846370776576 -> 1844708559072
	1844708559072 [label=AccumulateGrad]
	1844708558928 -> 1844708558688
	1846370776656 [label="stages.2.blocks.19.token_mixer.dwconv_hw.bias
 (48)" fillcolor=lightblue]
	1846370776656 -> 1844708558928
	1844708558928 [label=AccumulateGrad]
	1844708558640 -> 1844708558544
	1844708558640 [label=ConvolutionBackward0]
	1844708558736 -> 1844708558640
	1844708560080 -> 1844708558640
	1846370776816 [label="stages.2.blocks.19.token_mixer.dwconv_w.weight
 (48, 1, 1, 11)" fillcolor=lightblue]
	1846370776816 -> 1844708560080
	1844708560080 [label=AccumulateGrad]
	1844708559456 -> 1844708558640
	1846370776896 [label="stages.2.blocks.19.token_mixer.dwconv_w.bias
 (48)" fillcolor=lightblue]
	1846370776896 -> 1844708559456
	1844708559456 [label=AccumulateGrad]
	1844708558784 -> 1844708558544
	1844708558784 [label=ConvolutionBackward0]
	1844708558736 -> 1844708558784
	1844708559360 -> 1844708558784
	1846370777056 [label="stages.2.blocks.19.token_mixer.dwconv_h.weight
 (48, 1, 11, 1)" fillcolor=lightblue]
	1846370777056 -> 1844708559360
	1844708559360 [label=AccumulateGrad]
	1844708559840 -> 1844708558784
	1846370777136 [label="stages.2.blocks.19.token_mixer.dwconv_h.bias
 (48)" fillcolor=lightblue]
	1846370777136 -> 1844708559840
	1844708559840 [label=AccumulateGrad]
	1844708558496 -> 1844708558352
	1846370777296 [label="stages.2.blocks.19.norm.weight
 (384)" fillcolor=lightblue]
	1846370777296 -> 1844708558496
	1844708558496 [label=AccumulateGrad]
	1844708558448 -> 1844708558352
	1846370777376 [label="stages.2.blocks.19.norm.bias
 (384)" fillcolor=lightblue]
	1846370777376 -> 1844708558448
	1844708558448 [label=AccumulateGrad]
	1844708558304 -> 1844708558256
	1846370777856 [label="stages.2.blocks.19.mlp.fc1.weight
 (1536, 384, 1, 1)" fillcolor=lightblue]
	1846370777856 -> 1844708558304
	1844708558304 [label=AccumulateGrad]
	1844708558160 -> 1844708558256
	1846370777936 [label="stages.2.blocks.19.mlp.fc1.bias
 (1536)" fillcolor=lightblue]
	1846370777936 -> 1844708558160
	1844708558160 [label=AccumulateGrad]
	1844708558016 -> 1844708557920
	1846370778096 [label="stages.2.blocks.19.mlp.fc2.weight
 (384, 1536, 1, 1)" fillcolor=lightblue]
	1846370778096 -> 1844708558016
	1844708558016 [label=AccumulateGrad]
	1844708557968 -> 1844708557920
	1846370778176 [label="stages.2.blocks.19.mlp.fc2.bias
 (384)" fillcolor=lightblue]
	1846370778176 -> 1844708557968
	1844708557968 [label=AccumulateGrad]
	1844708557872 -> 1844708557776
	1844708557872 [label=ReshapeAliasBackward0]
	1844708558400 -> 1844708557872
	1846370778016 [label="stages.2.blocks.19.gamma
 (384)" fillcolor=lightblue]
	1846370778016 -> 1844708558400
	1844708558400 [label=AccumulateGrad]
	1844708557632 -> 1844708113952
	1844708557440 -> 1844708557296
	1844708557440 [label=ConvolutionBackward0]
	1844708557488 -> 1844708557440
	1844708557824 -> 1844708557440
	1846370778416 [label="stages.2.blocks.20.token_mixer.dwconv_hw.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	1846370778416 -> 1844708557824
	1844708557824 [label=AccumulateGrad]
	1844708557680 -> 1844708557440
	1846370778496 [label="stages.2.blocks.20.token_mixer.dwconv_hw.bias
 (48)" fillcolor=lightblue]
	1846370778496 -> 1844708557680
	1844708557680 [label=AccumulateGrad]
	1844708557392 -> 1844708557296
	1844708557392 [label=ConvolutionBackward0]
	1844708557488 -> 1844708557392
	1844708558832 -> 1844708557392
	1846370778656 [label="stages.2.blocks.20.token_mixer.dwconv_w.weight
 (48, 1, 1, 11)" fillcolor=lightblue]
	1846370778656 -> 1844708558832
	1844708558832 [label=AccumulateGrad]
	1844708558208 -> 1844708557392
	1846370778736 [label="stages.2.blocks.20.token_mixer.dwconv_w.bias
 (48)" fillcolor=lightblue]
	1846370778736 -> 1844708558208
	1844708558208 [label=AccumulateGrad]
	1844708557536 -> 1844708557296
	1844708557536 [label=ConvolutionBackward0]
	1844708557488 -> 1844708557536
	1844708558112 -> 1844708557536
	1846370778896 [label="stages.2.blocks.20.token_mixer.dwconv_h.weight
 (48, 1, 11, 1)" fillcolor=lightblue]
	1846370778896 -> 1844708558112
	1844708558112 [label=AccumulateGrad]
	1844708558592 -> 1844708557536
	1846370778976 [label="stages.2.blocks.20.token_mixer.dwconv_h.bias
 (48)" fillcolor=lightblue]
	1846370778976 -> 1844708558592
	1844708558592 [label=AccumulateGrad]
	1844708557248 -> 1844708557104
	1846371090496 [label="stages.2.blocks.20.norm.weight
 (384)" fillcolor=lightblue]
	1846371090496 -> 1844708557248
	1844708557248 [label=AccumulateGrad]
	1844708557200 -> 1844708557104
	1846371090576 [label="stages.2.blocks.20.norm.bias
 (384)" fillcolor=lightblue]
	1846371090576 -> 1844708557200
	1844708557200 [label=AccumulateGrad]
	1844708557056 -> 1844708557008
	1846371090976 [label="stages.2.blocks.20.mlp.fc1.weight
 (1536, 384, 1, 1)" fillcolor=lightblue]
	1846371090976 -> 1844708557056
	1844708557056 [label=AccumulateGrad]
	1844708556912 -> 1844708557008
	1846371091056 [label="stages.2.blocks.20.mlp.fc1.bias
 (1536)" fillcolor=lightblue]
	1846371091056 -> 1844708556912
	1844708556912 [label=AccumulateGrad]
	1844708114336 -> 1844708114240
	1846371091216 [label="stages.2.blocks.20.mlp.fc2.weight
 (384, 1536, 1, 1)" fillcolor=lightblue]
	1846371091216 -> 1844708114336
	1844708114336 [label=AccumulateGrad]
	1844708114288 -> 1844708114240
	1846371091296 [label="stages.2.blocks.20.mlp.fc2.bias
 (384)" fillcolor=lightblue]
	1846371091296 -> 1844708114288
	1844708114288 [label=AccumulateGrad]
	1844708114192 -> 1844708114096
	1844708114192 [label=ReshapeAliasBackward0]
	1844708557152 -> 1844708114192
	1846371091136 [label="stages.2.blocks.20.gamma
 (384)" fillcolor=lightblue]
	1846371091136 -> 1844708557152
	1844708557152 [label=AccumulateGrad]
	1844708113952 -> 1844708112704
	1844708113760 -> 1844708113616
	1844708113760 [label=ConvolutionBackward0]
	1844708113808 -> 1844708113760
	1844708114144 -> 1844708113760
	1846371091536 [label="stages.2.blocks.21.token_mixer.dwconv_hw.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	1846371091536 -> 1844708114144
	1844708114144 [label=AccumulateGrad]
	1844708114000 -> 1844708113760
	1846371091616 [label="stages.2.blocks.21.token_mixer.dwconv_hw.bias
 (48)" fillcolor=lightblue]
	1846371091616 -> 1844708114000
	1844708114000 [label=AccumulateGrad]
	1844708113712 -> 1844708113616
	1844708113712 [label=ConvolutionBackward0]
	1844708113808 -> 1844708113712
	1844708114048 -> 1844708113712
	1846371091776 [label="stages.2.blocks.21.token_mixer.dwconv_w.weight
 (48, 1, 1, 11)" fillcolor=lightblue]
	1846371091776 -> 1844708114048
	1844708114048 [label=AccumulateGrad]
	1844708557584 -> 1844708113712
	1846371091856 [label="stages.2.blocks.21.token_mixer.dwconv_w.bias
 (48)" fillcolor=lightblue]
	1846371091856 -> 1844708557584
	1844708557584 [label=AccumulateGrad]
	1844708113856 -> 1844708113616
	1844708113856 [label=ConvolutionBackward0]
	1844708113808 -> 1844708113856
	1844708556864 -> 1844708113856
	1846371092016 [label="stages.2.blocks.21.token_mixer.dwconv_h.weight
 (48, 1, 11, 1)" fillcolor=lightblue]
	1846371092016 -> 1844708556864
	1844708556864 [label=AccumulateGrad]
	1844708557344 -> 1844708113856
	1846371092096 [label="stages.2.blocks.21.token_mixer.dwconv_h.bias
 (48)" fillcolor=lightblue]
	1846371092096 -> 1844708557344
	1844708557344 [label=AccumulateGrad]
	1844708113568 -> 1844708113424
	1846371092256 [label="stages.2.blocks.21.norm.weight
 (384)" fillcolor=lightblue]
	1846371092256 -> 1844708113568
	1844708113568 [label=AccumulateGrad]
	1844708113520 -> 1844708113424
	1846371092336 [label="stages.2.blocks.21.norm.bias
 (384)" fillcolor=lightblue]
	1846371092336 -> 1844708113520
	1844708113520 [label=AccumulateGrad]
	1844708113376 -> 1844708113328
	1846371092736 [label="stages.2.blocks.21.mlp.fc1.weight
 (1536, 384, 1, 1)" fillcolor=lightblue]
	1846371092736 -> 1844708113376
	1844708113376 [label=AccumulateGrad]
	1844708113232 -> 1844708113328
	1846371092816 [label="stages.2.blocks.21.mlp.fc1.bias
 (1536)" fillcolor=lightblue]
	1846371092816 -> 1844708113232
	1844708113232 [label=AccumulateGrad]
	1844708113088 -> 1844708112992
	1846371092976 [label="stages.2.blocks.21.mlp.fc2.weight
 (384, 1536, 1, 1)" fillcolor=lightblue]
	1846371092976 -> 1844708113088
	1844708113088 [label=AccumulateGrad]
	1844708113040 -> 1844708112992
	1846371093056 [label="stages.2.blocks.21.mlp.fc2.bias
 (384)" fillcolor=lightblue]
	1846371093056 -> 1844708113040
	1844708113040 [label=AccumulateGrad]
	1844708112944 -> 1844708112848
	1844708112944 [label=ReshapeAliasBackward0]
	1844708113472 -> 1844708112944
	1846371092896 [label="stages.2.blocks.21.gamma
 (384)" fillcolor=lightblue]
	1846371092896 -> 1844708113472
	1844708113472 [label=AccumulateGrad]
	1844708112704 -> 1844708111456
	1844708112512 -> 1844708112368
	1844708112512 [label=ConvolutionBackward0]
	1844708112560 -> 1844708112512
	1844708112896 -> 1844708112512
	1846371093296 [label="stages.2.blocks.22.token_mixer.dwconv_hw.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	1846371093296 -> 1844708112896
	1844708112896 [label=AccumulateGrad]
	1844708112752 -> 1844708112512
	1846371093376 [label="stages.2.blocks.22.token_mixer.dwconv_hw.bias
 (48)" fillcolor=lightblue]
	1846371093376 -> 1844708112752
	1844708112752 [label=AccumulateGrad]
	1844708112464 -> 1844708112368
	1844708112464 [label=ConvolutionBackward0]
	1844708112560 -> 1844708112464
	1844708113904 -> 1844708112464
	1846371093536 [label="stages.2.blocks.22.token_mixer.dwconv_w.weight
 (48, 1, 1, 11)" fillcolor=lightblue]
	1846371093536 -> 1844708113904
	1844708113904 [label=AccumulateGrad]
	1844708113280 -> 1844708112464
	1846371093616 [label="stages.2.blocks.22.token_mixer.dwconv_w.bias
 (48)" fillcolor=lightblue]
	1846371093616 -> 1844708113280
	1844708113280 [label=AccumulateGrad]
	1844708112608 -> 1844708112368
	1844708112608 [label=ConvolutionBackward0]
	1844708112560 -> 1844708112608
	1844708113184 -> 1844708112608
	1846371093776 [label="stages.2.blocks.22.token_mixer.dwconv_h.weight
 (48, 1, 11, 1)" fillcolor=lightblue]
	1846371093776 -> 1844708113184
	1844708113184 [label=AccumulateGrad]
	1844708113664 -> 1844708112608
	1846371093856 [label="stages.2.blocks.22.token_mixer.dwconv_h.bias
 (48)" fillcolor=lightblue]
	1846371093856 -> 1844708113664
	1844708113664 [label=AccumulateGrad]
	1844708112320 -> 1844708112176
	1846371094016 [label="stages.2.blocks.22.norm.weight
 (384)" fillcolor=lightblue]
	1846371094016 -> 1844708112320
	1844708112320 [label=AccumulateGrad]
	1844708112272 -> 1844708112176
	1846371094096 [label="stages.2.blocks.22.norm.bias
 (384)" fillcolor=lightblue]
	1846371094096 -> 1844708112272
	1844708112272 [label=AccumulateGrad]
	1844708112128 -> 1844708112080
	1846371094576 [label="stages.2.blocks.22.mlp.fc1.weight
 (1536, 384, 1, 1)" fillcolor=lightblue]
	1846371094576 -> 1844708112128
	1844708112128 [label=AccumulateGrad]
	1844708111984 -> 1844708112080
	1846371094656 [label="stages.2.blocks.22.mlp.fc1.bias
 (1536)" fillcolor=lightblue]
	1846371094656 -> 1844708111984
	1844708111984 [label=AccumulateGrad]
	1844708111840 -> 1844708111744
	1846371094816 [label="stages.2.blocks.22.mlp.fc2.weight
 (384, 1536, 1, 1)" fillcolor=lightblue]
	1846371094816 -> 1844708111840
	1844708111840 [label=AccumulateGrad]
	1844708111792 -> 1844708111744
	1846371094896 [label="stages.2.blocks.22.mlp.fc2.bias
 (384)" fillcolor=lightblue]
	1846371094896 -> 1844708111792
	1844708111792 [label=AccumulateGrad]
	1844708111696 -> 1844708111600
	1844708111696 [label=ReshapeAliasBackward0]
	1844708112224 -> 1844708111696
	1846371094736 [label="stages.2.blocks.22.gamma
 (384)" fillcolor=lightblue]
	1846371094736 -> 1844708112224
	1844708112224 [label=AccumulateGrad]
	1844708111456 -> 1844708110208
	1844708111264 -> 1844708111120
	1844708111264 [label=ConvolutionBackward0]
	1844708111312 -> 1844708111264
	1844708111648 -> 1844708111264
	1846371095136 [label="stages.2.blocks.23.token_mixer.dwconv_hw.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	1846371095136 -> 1844708111648
	1844708111648 [label=AccumulateGrad]
	1844708111504 -> 1844708111264
	1846371095216 [label="stages.2.blocks.23.token_mixer.dwconv_hw.bias
 (48)" fillcolor=lightblue]
	1846371095216 -> 1844708111504
	1844708111504 [label=AccumulateGrad]
	1844708111216 -> 1844708111120
	1844708111216 [label=ConvolutionBackward0]
	1844708111312 -> 1844708111216
	1844708112656 -> 1844708111216
	1846371095376 [label="stages.2.blocks.23.token_mixer.dwconv_w.weight
 (48, 1, 1, 11)" fillcolor=lightblue]
	1846371095376 -> 1844708112656
	1844708112656 [label=AccumulateGrad]
	1844708112032 -> 1844708111216
	1846371095456 [label="stages.2.blocks.23.token_mixer.dwconv_w.bias
 (48)" fillcolor=lightblue]
	1846371095456 -> 1844708112032
	1844708112032 [label=AccumulateGrad]
	1844708111360 -> 1844708111120
	1844708111360 [label=ConvolutionBackward0]
	1844708111312 -> 1844708111360
	1844708111936 -> 1844708111360
	1846371095616 [label="stages.2.blocks.23.token_mixer.dwconv_h.weight
 (48, 1, 11, 1)" fillcolor=lightblue]
	1846371095616 -> 1844708111936
	1844708111936 [label=AccumulateGrad]
	1844708112416 -> 1844708111360
	1846371095696 [label="stages.2.blocks.23.token_mixer.dwconv_h.bias
 (48)" fillcolor=lightblue]
	1846371095696 -> 1844708112416
	1844708112416 [label=AccumulateGrad]
	1844708111072 -> 1844708110928
	1846371095856 [label="stages.2.blocks.23.norm.weight
 (384)" fillcolor=lightblue]
	1846371095856 -> 1844708111072
	1844708111072 [label=AccumulateGrad]
	1844708111024 -> 1844708110928
	1846371095936 [label="stages.2.blocks.23.norm.bias
 (384)" fillcolor=lightblue]
	1846371095936 -> 1844708111024
	1844708111024 [label=AccumulateGrad]
	1844708110880 -> 1844708110832
	1846371096336 [label="stages.2.blocks.23.mlp.fc1.weight
 (1536, 384, 1, 1)" fillcolor=lightblue]
	1846371096336 -> 1844708110880
	1844708110880 [label=AccumulateGrad]
	1844708110736 -> 1844708110832
	1846371096416 [label="stages.2.blocks.23.mlp.fc1.bias
 (1536)" fillcolor=lightblue]
	1846371096416 -> 1844708110736
	1844708110736 [label=AccumulateGrad]
	1844708110592 -> 1844708110496
	1846371096576 [label="stages.2.blocks.23.mlp.fc2.weight
 (384, 1536, 1, 1)" fillcolor=lightblue]
	1846371096576 -> 1844708110592
	1844708110592 [label=AccumulateGrad]
	1844708110544 -> 1844708110496
	1846371096656 [label="stages.2.blocks.23.mlp.fc2.bias
 (384)" fillcolor=lightblue]
	1846371096656 -> 1844708110544
	1844708110544 [label=AccumulateGrad]
	1844708110448 -> 1844708110352
	1844708110448 [label=ReshapeAliasBackward0]
	1844708110976 -> 1844708110448
	1846371096496 [label="stages.2.blocks.23.gamma
 (384)" fillcolor=lightblue]
	1846371096496 -> 1844708110976
	1844708110976 [label=AccumulateGrad]
	1844708110208 -> 1844708108960
	1844708110016 -> 1844708109872
	1844708110016 [label=ConvolutionBackward0]
	1844708110064 -> 1844708110016
	1844708110400 -> 1844708110016
	1846371096896 [label="stages.2.blocks.24.token_mixer.dwconv_hw.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	1846371096896 -> 1844708110400
	1844708110400 [label=AccumulateGrad]
	1844708110256 -> 1844708110016
	1846371096976 [label="stages.2.blocks.24.token_mixer.dwconv_hw.bias
 (48)" fillcolor=lightblue]
	1846371096976 -> 1844708110256
	1844708110256 [label=AccumulateGrad]
	1844708109968 -> 1844708109872
	1844708109968 [label=ConvolutionBackward0]
	1844708110064 -> 1844708109968
	1844708111408 -> 1844708109968
	1846371097136 [label="stages.2.blocks.24.token_mixer.dwconv_w.weight
 (48, 1, 1, 11)" fillcolor=lightblue]
	1846371097136 -> 1844708111408
	1844708111408 [label=AccumulateGrad]
	1844708110784 -> 1844708109968
	1846371097216 [label="stages.2.blocks.24.token_mixer.dwconv_w.bias
 (48)" fillcolor=lightblue]
	1846371097216 -> 1844708110784
	1844708110784 [label=AccumulateGrad]
	1844708110112 -> 1844708109872
	1844708110112 [label=ConvolutionBackward0]
	1844708110064 -> 1844708110112
	1844708110688 -> 1844708110112
	1846371097376 [label="stages.2.blocks.24.token_mixer.dwconv_h.weight
 (48, 1, 11, 1)" fillcolor=lightblue]
	1846371097376 -> 1844708110688
	1844708110688 [label=AccumulateGrad]
	1844708111168 -> 1844708110112
	1846371097456 [label="stages.2.blocks.24.token_mixer.dwconv_h.bias
 (48)" fillcolor=lightblue]
	1846371097456 -> 1844708111168
	1844708111168 [label=AccumulateGrad]
	1844708109824 -> 1844708109680
	1846371097616 [label="stages.2.blocks.24.norm.weight
 (384)" fillcolor=lightblue]
	1846371097616 -> 1844708109824
	1844708109824 [label=AccumulateGrad]
	1844708109776 -> 1844708109680
	1846371097696 [label="stages.2.blocks.24.norm.bias
 (384)" fillcolor=lightblue]
	1846371097696 -> 1844708109776
	1844708109776 [label=AccumulateGrad]
	1844708109632 -> 1844708109584
	1846371098176 [label="stages.2.blocks.24.mlp.fc1.weight
 (1536, 384, 1, 1)" fillcolor=lightblue]
	1846371098176 -> 1844708109632
	1844708109632 [label=AccumulateGrad]
	1844708109488 -> 1844708109584
	1846371098256 [label="stages.2.blocks.24.mlp.fc1.bias
 (1536)" fillcolor=lightblue]
	1846371098256 -> 1844708109488
	1844708109488 [label=AccumulateGrad]
	1844708109344 -> 1844708109248
	1846371098416 [label="stages.2.blocks.24.mlp.fc2.weight
 (384, 1536, 1, 1)" fillcolor=lightblue]
	1846371098416 -> 1844708109344
	1844708109344 [label=AccumulateGrad]
	1844708109296 -> 1844708109248
	1846371098496 [label="stages.2.blocks.24.mlp.fc2.bias
 (384)" fillcolor=lightblue]
	1846371098496 -> 1844708109296
	1844708109296 [label=AccumulateGrad]
	1844708109200 -> 1844708109104
	1844708109200 [label=ReshapeAliasBackward0]
	1844708109728 -> 1844708109200
	1846371098336 [label="stages.2.blocks.24.gamma
 (384)" fillcolor=lightblue]
	1846371098336 -> 1844708109728
	1844708109728 [label=AccumulateGrad]
	1844708108960 -> 1844708107856
	1844708108768 -> 1844708108624
	1844708108768 [label=ConvolutionBackward0]
	1844708108816 -> 1844708108768
	1844708109152 -> 1844708108768
	1846371098736 [label="stages.2.blocks.25.token_mixer.dwconv_hw.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	1846371098736 -> 1844708109152
	1844708109152 [label=AccumulateGrad]
	1844708109008 -> 1844708108768
	1846371098816 [label="stages.2.blocks.25.token_mixer.dwconv_hw.bias
 (48)" fillcolor=lightblue]
	1846371098816 -> 1844708109008
	1844708109008 [label=AccumulateGrad]
	1844708108720 -> 1844708108624
	1844708108720 [label=ConvolutionBackward0]
	1844708108816 -> 1844708108720
	1844708110160 -> 1844708108720
	1846371098976 [label="stages.2.blocks.25.token_mixer.dwconv_w.weight
 (48, 1, 1, 11)" fillcolor=lightblue]
	1846371098976 -> 1844708110160
	1844708110160 [label=AccumulateGrad]
	1844708109536 -> 1844708108720
	1846371099056 [label="stages.2.blocks.25.token_mixer.dwconv_w.bias
 (48)" fillcolor=lightblue]
	1846371099056 -> 1844708109536
	1844708109536 [label=AccumulateGrad]
	1844708108864 -> 1844708108624
	1844708108864 [label=ConvolutionBackward0]
	1844708108816 -> 1844708108864
	1844708109440 -> 1844708108864
	1846371099216 [label="stages.2.blocks.25.token_mixer.dwconv_h.weight
 (48, 1, 11, 1)" fillcolor=lightblue]
	1846371099216 -> 1844708109440
	1844708109440 [label=AccumulateGrad]
	1844708109920 -> 1844708108864
	1846371099296 [label="stages.2.blocks.25.token_mixer.dwconv_h.bias
 (48)" fillcolor=lightblue]
	1846371099296 -> 1844708109920
	1844708109920 [label=AccumulateGrad]
	1844708108576 -> 1844708108432
	1846371099456 [label="stages.2.blocks.25.norm.weight
 (384)" fillcolor=lightblue]
	1846371099456 -> 1844708108576
	1844708108576 [label=AccumulateGrad]
	1844708108528 -> 1844708108432
	1846371099536 [label="stages.2.blocks.25.norm.bias
 (384)" fillcolor=lightblue]
	1846371099536 -> 1844708108528
	1844708108528 [label=AccumulateGrad]
	1844708108384 -> 1844708108144
	1846371099936 [label="stages.2.blocks.25.mlp.fc1.weight
 (1536, 384, 1, 1)" fillcolor=lightblue]
	1846371099936 -> 1844708108384
	1844708108384 [label=AccumulateGrad]
	1844708108192 -> 1844708108144
	1846371100016 [label="stages.2.blocks.25.mlp.fc1.bias
 (1536)" fillcolor=lightblue]
	1846371100016 -> 1844708108192
	1844708108192 [label=AccumulateGrad]
	1844708107712 -> 1844708107952
	1846371100176 [label="stages.2.blocks.25.mlp.fc2.weight
 (384, 1536, 1, 1)" fillcolor=lightblue]
	1846371100176 -> 1844708107712
	1844708107712 [label=AccumulateGrad]
	1844708108000 -> 1844708107952
	1846371100256 [label="stages.2.blocks.25.mlp.fc2.bias
 (384)" fillcolor=lightblue]
	1846371100256 -> 1844708108000
	1844708108000 [label=AccumulateGrad]
	1844708108048 -> 1844708107808
	1844708108048 [label=ReshapeAliasBackward0]
	1844708108336 -> 1844708108048
	1846371100096 [label="stages.2.blocks.25.gamma
 (384)" fillcolor=lightblue]
	1846371100096 -> 1844708108336
	1844708108336 [label=AccumulateGrad]
	1844708107856 -> 1844708106032
	1844708107184 -> 1844708107040
	1844708107184 [label=ConvolutionBackward0]
	1844708107424 -> 1844708107184
	1844708107904 -> 1844708107184
	1846371100496 [label="stages.2.blocks.26.token_mixer.dwconv_hw.weight
 (48, 1, 3, 3)" fillcolor=lightblue]
	1846371100496 -> 1844708107904
	1844708107904 [label=AccumulateGrad]
	1844708107568 -> 1844708107184
	1846371100576 [label="stages.2.blocks.26.token_mixer.dwconv_hw.bias
 (48)" fillcolor=lightblue]
	1846371100576 -> 1844708107568
	1844708107568 [label=AccumulateGrad]
	1844708106896 -> 1844708107040
	1844708106896 [label=ConvolutionBackward0]
	1844708107424 -> 1844708106896
	1844708108912 -> 1844708106896
	1846371100736 [label="stages.2.blocks.26.token_mixer.dwconv_w.weight
 (48, 1, 1, 11)" fillcolor=lightblue]
	1846371100736 -> 1844708108912
	1844708108912 [label=AccumulateGrad]
	1844708108480 -> 1844708106896
	1846371100816 [label="stages.2.blocks.26.token_mixer.dwconv_w.bias
 (48)" fillcolor=lightblue]
	1846371100816 -> 1844708108480
	1844708108480 [label=AccumulateGrad]
	1844708107280 -> 1844708107040
	1844708107280 [label=ConvolutionBackward0]
	1844708107424 -> 1844708107280
	1844708108240 -> 1844708107280
	1846371100976 [label="stages.2.blocks.26.token_mixer.dwconv_h.weight
 (48, 1, 11, 1)" fillcolor=lightblue]
	1846371100976 -> 1844708108240
	1844708108240 [label=AccumulateGrad]
	1844708108672 -> 1844708107280
	1846371101056 [label="stages.2.blocks.26.token_mixer.dwconv_h.bias
 (48)" fillcolor=lightblue]
	1846371101056 -> 1844708108672
	1844708108672 [label=AccumulateGrad]
	1844708107616 -> 1844708107232
	1846371101216 [label="stages.2.blocks.26.norm.weight
 (384)" fillcolor=lightblue]
	1846371101216 -> 1844708107616
	1844708107616 [label=AccumulateGrad]
	1844708107088 -> 1844708107232
	1846371101296 [label="stages.2.blocks.26.norm.bias
 (384)" fillcolor=lightblue]
	1846371101296 -> 1844708107088
	1844708107088 [label=AccumulateGrad]
	1844708106704 -> 1844708106848
	1846371101776 [label="stages.2.blocks.26.mlp.fc1.weight
 (1536, 384, 1, 1)" fillcolor=lightblue]
	1846371101776 -> 1844708106704
	1844708106704 [label=AccumulateGrad]
	1844708106416 -> 1844708106848
	1846371101856 [label="stages.2.blocks.26.mlp.fc1.bias
 (1536)" fillcolor=lightblue]
	1846371101856 -> 1844708106416
	1844708106416 [label=AccumulateGrad]
	1844708106800 -> 1844708106944
	1846371102016 [label="stages.2.blocks.26.mlp.fc2.weight
 (384, 1536, 1, 1)" fillcolor=lightblue]
	1846371102016 -> 1844708106800
	1844708106800 [label=AccumulateGrad]
	1844708106512 -> 1844708106944
	1846371102096 [label="stages.2.blocks.26.mlp.fc2.bias
 (384)" fillcolor=lightblue]
	1846371102096 -> 1844708106512
	1844708106512 [label=AccumulateGrad]
	1844708106464 -> 1844708106608
	1844708106464 [label=ReshapeAliasBackward0]
	1844708107328 -> 1844708106464
	1846371101936 [label="stages.2.blocks.26.gamma
 (384)" fillcolor=lightblue]
	1846371101936 -> 1844708107328
	1844708107328 [label=AccumulateGrad]
	1844708106032 -> 1844708105408
	1844708105840 -> 1844708104208
	1846273490864 [label="stages.3.downsample.0.weight
 (384)" fillcolor=lightblue]
	1846273490864 -> 1844708105840
	1844708105840 [label=AccumulateGrad]
	1844708105552 -> 1844708104208
	1846167694736 [label="stages.3.downsample.0.bias
 (384)" fillcolor=lightblue]
	1846167694736 -> 1844708105552
	1844708105552 [label=AccumulateGrad]
	1844708105264 -> 1844708102096
	1846371102496 [label="stages.3.downsample.1.weight
 (768, 384, 2, 2)" fillcolor=lightblue]
	1846371102496 -> 1844708105264
	1844708105264 [label=AccumulateGrad]
	1844708105648 -> 1844708102096
	1846371102576 [label="stages.3.downsample.1.bias
 (768)" fillcolor=lightblue]
	1846371102576 -> 1844708105648
	1844708105648 [label=AccumulateGrad]
	1844708106080 -> 1844708105600
	1844708106080 [label=ConvolutionBackward0]
	1844708103296 -> 1844708106080
	1844708106368 -> 1844708106080
	1846371102816 [label="stages.3.blocks.0.token_mixer.dwconv_hw.weight
 (96, 1, 3, 3)" fillcolor=lightblue]
	1846371102816 -> 1844708106368
	1844708106368 [label=AccumulateGrad]
	1844708106128 -> 1844708106080
	1846371102896 [label="stages.3.blocks.0.token_mixer.dwconv_hw.bias
 (96)" fillcolor=lightblue]
	1846371102896 -> 1844708106128
	1844708106128 [label=AccumulateGrad]
	1844708104688 -> 1844708105600
	1844708104688 [label=ConvolutionBackward0]
	1844708103296 -> 1844708104688
	1844708106752 -> 1844708104688
	1846371103056 [label="stages.3.blocks.0.token_mixer.dwconv_w.weight
 (96, 1, 1, 11)" fillcolor=lightblue]
	1846371103056 -> 1844708106752
	1844708106752 [label=AccumulateGrad]
	1844708104880 -> 1844708104688
	1846371103136 [label="stages.3.blocks.0.token_mixer.dwconv_w.bias
 (96)" fillcolor=lightblue]
	1846371103136 -> 1844708104880
	1844708104880 [label=AccumulateGrad]
	1844708105360 -> 1844708105600
	1844708105360 [label=ConvolutionBackward0]
	1844708103296 -> 1844708105360
	1844708107760 -> 1844708105360
	1846371103296 [label="stages.3.blocks.0.token_mixer.dwconv_h.weight
 (96, 1, 11, 1)" fillcolor=lightblue]
	1846371103296 -> 1844708107760
	1844708107760 [label=AccumulateGrad]
	1844708107136 -> 1844708105360
	1846371103376 [label="stages.3.blocks.0.token_mixer.dwconv_h.bias
 (96)" fillcolor=lightblue]
	1846371103376 -> 1844708107136
	1844708107136 [label=AccumulateGrad]
	1844708105504 -> 1844708104784
	1846371103536 [label="stages.3.blocks.0.norm.weight
 (768)" fillcolor=lightblue]
	1846371103536 -> 1844708105504
	1844708105504 [label=AccumulateGrad]
	1844708104400 -> 1844708104784
	1846371103616 [label="stages.3.blocks.0.norm.bias
 (768)" fillcolor=lightblue]
	1846371103616 -> 1844708104400
	1844708104400 [label=AccumulateGrad]
	1844708104976 -> 1844708105984
	1846371104096 [label="stages.3.blocks.0.mlp.fc1.weight
 (2304, 768, 1, 1)" fillcolor=lightblue]
	1846371104096 -> 1844708104976
	1844708104976 [label=AccumulateGrad]
	1844708104064 -> 1844708105984
	1846371104176 [label="stages.3.blocks.0.mlp.fc1.bias
 (2304)" fillcolor=lightblue]
	1846371104176 -> 1844708104064
	1844708104064 [label=AccumulateGrad]
	1844708099792 -> 1844708104496
	1846371104336 [label="stages.3.blocks.0.mlp.fc2.weight
 (768, 2304, 1, 1)" fillcolor=lightblue]
	1846371104336 -> 1844708099792
	1844708099792 [label=AccumulateGrad]
	1844708102288 -> 1844708104496
	1846371104416 [label="stages.3.blocks.0.mlp.fc2.bias
 (768)" fillcolor=lightblue]
	1846371104416 -> 1844708102288
	1844708102288 [label=AccumulateGrad]
	1844708103584 -> 1844708102816
	1844708103584 [label=ReshapeAliasBackward0]
	1844708106320 -> 1844708103584
	1846371104256 [label="stages.3.blocks.0.gamma
 (768)" fillcolor=lightblue]
	1846371104256 -> 1844708106320
	1844708106320 [label=AccumulateGrad]
	1844708102096 -> 1844708100944
	1844708102768 -> 1844708101424
	1844708102768 [label=ConvolutionBackward0]
	1844708102864 -> 1844708102768
	1844708103728 -> 1844708102768
	1846371104656 [label="stages.3.blocks.1.token_mixer.dwconv_hw.weight
 (96, 1, 3, 3)" fillcolor=lightblue]
	1846371104656 -> 1844708103728
	1844708103728 [label=AccumulateGrad]
	1844708104448 -> 1844708102768
	1846371104736 [label="stages.3.blocks.1.token_mixer.dwconv_hw.bias
 (96)" fillcolor=lightblue]
	1846371104736 -> 1844708104448
	1844708104448 [label=AccumulateGrad]
	1844708099744 -> 1844708101424
	1844708099744 [label=ConvolutionBackward0]
	1844708102864 -> 1844708099744
	1844708103440 -> 1844708099744
	1846371104896 [label="stages.3.blocks.1.token_mixer.dwconv_w.weight
 (96, 1, 1, 11)" fillcolor=lightblue]
	1846371104896 -> 1844708103440
	1844708103440 [label=AccumulateGrad]
	1844708103920 -> 1844708099744
	1846371104976 [label="stages.3.blocks.1.token_mixer.dwconv_w.bias
 (96)" fillcolor=lightblue]
	1846371104976 -> 1844708103920
	1844708103920 [label=AccumulateGrad]
	1844708105216 -> 1844708101424
	1844708105216 [label=ConvolutionBackward0]
	1844708102864 -> 1844708105216
	1844708103632 -> 1844708105216
	1846371105136 [label="stages.3.blocks.1.token_mixer.dwconv_h.weight
 (96, 1, 11, 1)" fillcolor=lightblue]
	1846371105136 -> 1844708103632
	1844708103632 [label=AccumulateGrad]
	1844708105696 -> 1844708105216
	1846371105216 [label="stages.3.blocks.1.token_mixer.dwconv_h.bias
 (96)" fillcolor=lightblue]
	1846371105216 -> 1844708105696
	1844708105696 [label=AccumulateGrad]
	1844708102144 -> 1844708103152
	1846371105376 [label="stages.3.blocks.1.norm.weight
 (768)" fillcolor=lightblue]
	1846371105376 -> 1844708102144
	1844708102144 [label=AccumulateGrad]
	1844708101616 -> 1844708103152
	1846371105456 [label="stages.3.blocks.1.norm.bias
 (768)" fillcolor=lightblue]
	1846371105456 -> 1844708101616
	1844708101616 [label=AccumulateGrad]
	1844708101904 -> 1844708104112
	1846371105936 [label="stages.3.blocks.1.mlp.fc1.weight
 (2304, 768, 1, 1)" fillcolor=lightblue]
	1846371105936 -> 1844708101904
	1844708101904 [label=AccumulateGrad]
	1844708101568 -> 1844708104112
	1846371106016 [label="stages.3.blocks.1.mlp.fc1.bias
 (2304)" fillcolor=lightblue]
	1846371106016 -> 1844708101568
	1844708101568 [label=AccumulateGrad]
	1844708101712 -> 1844708100224
	1846371106176 [label="stages.3.blocks.1.mlp.fc2.weight
 (768, 2304, 1, 1)" fillcolor=lightblue]
	1846371106176 -> 1844708101712
	1844708101712 [label=AccumulateGrad]
	1844708103248 -> 1844708100224
	1846371106256 [label="stages.3.blocks.1.mlp.fc2.bias
 (768)" fillcolor=lightblue]
	1846371106256 -> 1844708103248
	1844708103248 [label=AccumulateGrad]
	1844708103008 -> 1844708101280
	1844708103008 [label=ReshapeAliasBackward0]
	1844708103968 -> 1844708103008
	1846371106096 [label="stages.3.blocks.1.gamma
 (768)" fillcolor=lightblue]
	1846371106096 -> 1844708103968
	1844708103968 [label=AccumulateGrad]
	1844708100944 -> 1846506518896
	1844708099456 -> 1844708099360
	1844708099456 [label=ConvolutionBackward0]
	1844708100416 -> 1844708099456
	1844708099936 -> 1844708099456
	1846371106496 [label="stages.3.blocks.2.token_mixer.dwconv_hw.weight
 (96, 1, 3, 3)" fillcolor=lightblue]
	1846371106496 -> 1844708099936
	1844708099936 [label=AccumulateGrad]
	1844708100464 -> 1844708099456
	1846371106576 [label="stages.3.blocks.2.token_mixer.dwconv_hw.bias
 (96)" fillcolor=lightblue]
	1846371106576 -> 1844708100464
	1844708100464 [label=AccumulateGrad]
	1844708098592 -> 1844708099360
	1844708098592 [label=ConvolutionBackward0]
	1844708100416 -> 1844708098592
	1844708104016 -> 1844708098592
	1846371106736 [label="stages.3.blocks.2.token_mixer.dwconv_w.weight
 (96, 1, 1, 11)" fillcolor=lightblue]
	1846371106736 -> 1844708104016
	1844708104016 [label=AccumulateGrad]
	1844708100176 -> 1844708098592
	1846371434560 [label="stages.3.blocks.2.token_mixer.dwconv_w.bias
 (96)" fillcolor=lightblue]
	1846371434560 -> 1844708100176
	1844708100176 [label=AccumulateGrad]
	1844708098688 -> 1844708099360
	1844708098688 [label=ConvolutionBackward0]
	1844708100416 -> 1844708098688
	1844708101088 -> 1844708098688
	1846371434720 [label="stages.3.blocks.2.token_mixer.dwconv_h.weight
 (96, 1, 11, 1)" fillcolor=lightblue]
	1846371434720 -> 1844708101088
	1844708101088 [label=AccumulateGrad]
	1844708104544 -> 1844708098688
	1846371434800 [label="stages.3.blocks.2.token_mixer.dwconv_h.bias
 (96)" fillcolor=lightblue]
	1846371434800 -> 1844708104544
	1844708104544 [label=AccumulateGrad]
	1844708098256 -> 1844708100128
	1846371434960 [label="stages.3.blocks.2.norm.weight
 (768)" fillcolor=lightblue]
	1846371434960 -> 1844708098256
	1844708098256 [label=AccumulateGrad]
	1844708100560 -> 1844708100128
	1846371435040 [label="stages.3.blocks.2.norm.bias
 (768)" fillcolor=lightblue]
	1846371435040 -> 1844708100560
	1844708100560 [label=AccumulateGrad]
	1844708099696 -> 1844708102576
	1846371435520 [label="stages.3.blocks.2.mlp.fc1.weight
 (2304, 768, 1, 1)" fillcolor=lightblue]
	1846371435520 -> 1844708099696
	1844708099696 [label=AccumulateGrad]
	1844708099024 -> 1844708102576
	1846371435600 [label="stages.3.blocks.2.mlp.fc1.bias
 (2304)" fillcolor=lightblue]
	1846371435600 -> 1844708099024
	1844708099024 [label=AccumulateGrad]
	1844708099168 -> 1844708100992
	1846371435760 [label="stages.3.blocks.2.mlp.fc2.weight
 (768, 2304, 1, 1)" fillcolor=lightblue]
	1846371435760 -> 1844708099168
	1844708099168 [label=AccumulateGrad]
	1844708100704 -> 1844708100992
	1846371435840 [label="stages.3.blocks.2.mlp.fc2.bias
 (768)" fillcolor=lightblue]
	1846371435840 -> 1844708100704
	1844708100704 [label=AccumulateGrad]
	1844708101760 -> 1846506518608
	1844708101760 [label=ReshapeAliasBackward0]
	1844708098736 -> 1844708101760
	1846371435680 [label="stages.3.blocks.2.gamma
 (768)" fillcolor=lightblue]
	1846371435680 -> 1844708098736
	1844708098736 [label=AccumulateGrad]
	1846506518896 -> 1846506518848
	1846552447728 -> 1846552448880
	1846552447728 [label=TBackward0]
	1846506515680 -> 1846552447728
	1846371435920 [label="head.fc1.weight
 (2304, 768)" fillcolor=lightblue]
	1846371435920 -> 1846506515680
	1846506515680 [label=AccumulateGrad]
	1846552448736 -> 1846552447104
	1846244806624 [label="head.norm.weight
 (2304)" fillcolor=lightblue]
	1846244806624 -> 1846552448736
	1846552448736 [label=AccumulateGrad]
	1846552446816 -> 1846552447104
	1846244806544 [label="head.norm.bias
 (2304)" fillcolor=lightblue]
	1846244806544 -> 1846552446816
	1846552446816 [label=AccumulateGrad]
	1846552455264 -> 1846552194992
	1846552455264 [label=TBackward0]
	1846552448352 -> 1846552455264
	1846167576848 [label="head.fc2.weight
 (1, 2304)" fillcolor=lightblue]
	1846167576848 -> 1846552448352
	1846552448352 [label=AccumulateGrad]
	1846552194992 -> 1844707884496
}
